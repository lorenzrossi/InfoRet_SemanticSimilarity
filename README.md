# InfoRet_SemanticSimilarity

Code and LaTeX paper of the project for Information Retrieval.
The first notebook is the data exploration notebook, where average lenghts, distribution of labels and most common words in the dataset are investigated.
Next, LSTM and BERT notebooks have been created. The notebooks contain, for each of the two algorithms, data preprocessing (such as tokenization and word embedding), model definition and performancess.

The SNLI dataset has been downloaded from Kaggle (https://www.kaggle.com/datasets/stanfordu/stanford-natural-language-inference-corpus), you just need your username and key to download data.
GloVe word embedding has been downloaded from the respective website.
