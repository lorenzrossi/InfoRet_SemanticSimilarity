{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzrossi/InfoRet_SemanticSimilarity/blob/main/InfoRet_Semantic_Similarity_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICord5RYWE9U",
        "outputId": "d04a4496-057a-40f8-902a-7b3af1094218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from opendatasets) (4.64.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2022.12.7)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2.25.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle->opendatasets) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers~=2.11.0\n",
            "  Downloading transformers-2.11.0-py3-none-any.whl (674 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m674.8/674.8 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers~=2.11.0) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers~=2.11.0) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers~=2.11.0) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers~=2.11.0) (2022.6.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tokenizers==0.7.0\n",
            "  Downloading tokenizers-0.7.0-cp38-cp38-manylinux1_x86_64.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from transformers~=2.11.0) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers~=2.11.0) (3.9.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers~=2.11.0) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers~=2.11.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers~=2.11.0) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers~=2.11.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers~=2.11.0) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers~=2.11.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers~=2.11.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers~=2.11.0) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=53c35ef2587405b9b20dc5756fd74d9a0955a47e7bf27efbe30f28780f9d5fd2\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.7.0 transformers-2.11.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreTrueAction(option_strings=['--no_train'], dest='no_train', nargs=0, const=True, default=False, type=None, choices=None, help=\"Don't train model, load model and quit\", metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, classification_report, hamming_loss\n",
        "import shutil \n",
        "import sys\n",
        "import time, datetime, json\n",
        "\n",
        "!pip install opendatasets\n",
        "import opendatasets as op\n",
        "\n",
        "import os\n",
        "\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "# NLTK\n",
        "import nltk as nlp\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import ngrams\n",
        "nlp.download('stopwords')\n",
        "nlp.download('popular')\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# PYTORCH\n",
        "!pip install transformers~=2.11.0\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, AdamWeightDecay, get_linear_schedule_with_warmup\n",
        "import random\n",
        "import gc\n",
        "\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--data_dir', default='data',\n",
        "                    help=\"Directory to download dataset\")\n",
        "parser.add_argument('--preprocessed_dir', default='preprocessed_data',\n",
        "                    help=\"Directory to save preprocessed datasets\")\n",
        "parser.add_argument('--model_dir', default=\"saved-model\",\n",
        "                    help=\"Directory to save model after training\")\n",
        "\n",
        "parser.add_argument('--config', default=\"config.ini\",\n",
        "                    help=\"INI file for model configuration\")\n",
        "\n",
        "parser.add_argument('--epochs', help=\"Number of epochs to train for\")\n",
        "parser.add_argument('--batch_size',\n",
        "                    help=\"Batch Size for Training/Validation/Testing on dataset\")\n",
        "\n",
        "parser.add_argument('--download_dataset', action='store_true',\n",
        "                    help=\"If set, download the dataset to a specified location\")\n",
        "parser.add_argument('--bert_size', default=\"base\", choices=[\"base\", \"large\"],\n",
        "                    help=\"Size of pretrained BERT to use (base or large)\")\n",
        "parser.add_argument('--cased', default=False,\n",
        "                    help=\"Use argument when you think casing is important\")\n",
        "parser.add_argument('--num_labels',\n",
        "                    help=\"Number of labels to classify for given dataset\")\n",
        "\n",
        "parser.add_argument('--output_attentions', action='store_true',\n",
        "                    help=\"Output attention values from BERT Model\")\n",
        "parser.add_argument('--output_hidden_states', action='store_true',\n",
        "                    help=\"Output embeddings generated from BERT layers\")\n",
        "parser.add_argument('--gpu', action='store_true',\n",
        "                    help=\"Use GPU for training if available\")\n",
        "parser.add_argument('--predict_on_test', action='store_true',\n",
        "                    help=\"Load model from file and run on test set\")\n",
        "parser.add_argument('--no_train', action='store_true',\n",
        "                    help=\"Don't train model, load model and quit\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q12KZ2lWFrG",
        "outputId": "b56eec96-76bd-47f1-8282-6b0b91c18c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-24 07:49:26--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-01-24 07:49:26--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2023-01-24 07:52:06 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "# bcc30972b8b9f25c2bc6c0a46d8f4d62"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ggx6Z93sUmMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a275e6-cfda-42f0-9557-5ed79fa5a9de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: lorenzrossi\n",
            "Your Kaggle Key: ··········\n",
            "Downloading stanford-natural-language-inference-corpus.zip to ./stanford-natural-language-inference-corpus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.4M/44.4M [00:00<00:00, 164MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "op.download(\"https://www.kaggle.com/datasets/stanfordu/stanford-natural-language-inference-corpus\")\n",
        "url = \"https://www.kaggle.com/datasets/stanfordu/stanford-natural-language-inference-corpus\"\n",
        "dataset_folder ='stanford-natural-language-inference-corpus'\n",
        "preprocessed_folder = 'snli-preprocessed'\n",
        "saved_model_location = 'saved_models'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SPECIAL_TOKENS = {\n",
        "    'CLS': ['[CLS]'],\n",
        "    'SEP': ['[SEP]']\n",
        "}\n",
        "\n",
        "SNLI_DATASET_URL = {\n",
        "    \"train_folder\": \"stanford-natural-language-inference-corpus/snli_1.0_train.csv\",\n",
        "    \"validation_folder\": \"stanford-natural-language-inference-corpus/snli_1.0_dev.csv\",\n",
        "    \"test_folder\": \"stanford-natural-language-inference-corpus/snli_1.0_test.csv\"\n",
        "}\n",
        "\n",
        "SNLI_FILE_NAMES = {\n",
        "    \"train\": \"snli_1.0_train.csv\",\n",
        "    \"validation\": \"snli_1.0_dev.csv\",\n",
        "    \"test\": \"snli_1.0_test.csv\"\n",
        "}"
      ],
      "metadata": {
        "id": "8vkkeS_WofOp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf-Jmdc7MjBR"
      },
      "source": [
        "# PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters for preprocessing, tokenization and word embedding\n",
        "\n",
        "max_len_tokens = 256\n",
        "\n",
        "dataset_labels = {\"contradiction\": 0,\n",
        "\"entailment\": 1,\n",
        "\"neutral\": 2}\n",
        "\n",
        "DATASET_LABELS = {}\n",
        "for k, v in dataset_labels.items():\n",
        "    DATASET_LABELS[k] = int(v)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f55f4d7b3113497f825d5d31b11510b8",
            "96a13aeaca894fb68ca07642d53536a4",
            "1b06068469124dda909d68e228446f0a",
            "0128d9e03daf4b0fb886da8c4be4ce68",
            "48ffaf79c5a945cf8e1297407fc9cc88",
            "a61e3057fa1d440fae4b85a361867efb",
            "0b511fcf2e1a4dc8b92902198a644bc9",
            "019988eb70554cf4b3577ee3adf92dc4",
            "70c1643f8ba9432ea00e3351332b869c",
            "19b2ebb0ac544c07bdf2a26d7b3afe0f",
            "81721714b478482da37d98ca053a3348"
          ]
        },
        "id": "lEbfO38XErXa",
        "outputId": "a0f620b7-07b2-4e66-b25d-d072bfade210"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f55f4d7b3113497f825d5d31b11510b8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_LABELS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ptd8LdNErXX",
        "outputId": "c3ff41e7-6e64-415e-8e9b-128c15b9ea3e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'contradiction': 0, 'entailment': 1, 'neutral': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SNLIDataset(object):\n",
        "    \"\"\"\n",
        "    Class to handle datasets and\n",
        "    preprocess them in order to pass them on\n",
        "    to the model for training/testing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, tokenizer, dataset_folder, preprocessed_folder, batch_size,\n",
        "        max_len_tokens, dataset_labels, download_dataset=False, use_padding=True\n",
        "    ):\n",
        "\n",
        "        self.dataset_folder = dataset_folder\n",
        "        self.preprocessed_folder = preprocessed_folder\n",
        "        self.batch_size = batch_size\n",
        "        self.use_padding = use_padding\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len_tokens = max_len_tokens\n",
        "\n",
        "        self.dataset_labels = dataset_labels\n",
        "\n",
        "        if download_dataset:\n",
        "            self.download_dataset()\n",
        "\n",
        "        train_data = os.path.join(self.dataset_folder, SNLI_FILE_NAMES[\"train\"])\n",
        "        validation_data = os.path.join(self.dataset_folder, SNLI_FILE_NAMES[\"validation\"])\n",
        "        test_data = os.path.join(self.dataset_folder, SNLI_FILE_NAMES[\"test\"])\n",
        "\n",
        "        self.train_raw = pd.read_csv(train_data, index_col=1)\n",
        "        self.train_raw = self.train_raw.sample(frac=0.2)\n",
        "        \n",
        "        self.eval_raw = pd.read_csv(validation_data, index_col=1)\n",
        "        #self.eval_raw = self.eval_raw.sample(frac=0.5)\n",
        "\n",
        "        self.test_raw = pd.read_csv(test_data, index_col=1)\n",
        "        #self.test_raw = self.test_raw.sample(frac=0.5)\n",
        "\n",
        "    def download_dataset(self):\n",
        "\n",
        "       print(\"Downloading SNLI Dataset in CSV format\")\n",
        "       \n",
        "       if not os.path.exists(self.dataset_folder):\n",
        "           os.mkdir(self.dataset_folder)\n",
        "       \n",
        "       download_location = self.dataset_folder\n",
        "       \n",
        "       train_data_url = SNLI_DATASET_URL[\"train\"]\n",
        "       validation_data_url = SNLI_DATASET_URL[\"validation\"]\n",
        "       test_data_url = SNLI_DATASET_URL[\"test\"]\n",
        "       \n",
        "       if os.path.exists(os.path.join(download_location)):\n",
        "           print(\"Test Data already present\")\n",
        "       \n",
        "       else:\n",
        "           dataset = op.download(url, out=download_location)\n",
        "       \n",
        "       print(f\"Dataset downloaded successfully in {download_location}\")\n",
        "       \n",
        "       return\n",
        "\n",
        "    def preprocess_dataset_util(self, dataset_df):\n",
        "    \n",
        "        tokenizer = self.tokenizer\n",
        "        labels_dict = self.dataset_labels\n",
        "        \n",
        "        def tokenize_sentence(tokenizer, input_sentence):\n",
        "        \n",
        "            return tokenizer.tokenize(input_sentence)\n",
        "            \n",
        "        sentence_A = dataset_df.sentence1.to_numpy()\n",
        "        sentence_B = dataset_df.sentence2.to_numpy()\n",
        "        labels = dataset_df.gold_label.to_numpy()            \n",
        "                 \n",
        "        sentence_A_tokens = []\n",
        "        sentence_B_tokens = []\n",
        "        processed_labels = []\n",
        "\n",
        "        for i, j, k in zip(sentence_A, sentence_B, labels):\n",
        "            try:\n",
        "                if k == '-':\n",
        "                    continue\n",
        "                \n",
        "                t1 = tokenize_sentence(tokenizer, i)\n",
        "                t2 = tokenize_sentence(tokenizer, j)\n",
        "                \n",
        "                sentence_A_tokens.append(t1)\n",
        "                sentence_B_tokens.append(t2)\n",
        "                \n",
        "                label = labels_dict[k]\n",
        "                processed_labels.append(label)\n",
        "            \n",
        "            except Exception as e:\n",
        "                \n",
        "                print(e)\n",
        "                print(\"Skipping over sentence pair!\")\n",
        "                \n",
        "                continue\n",
        "        \n",
        "        sentence_tokens = []\n",
        "        input_ids = []\n",
        "        token_lengths = []\n",
        "        \n",
        "        CLS_TOKEN = SPECIAL_TOKENS['CLS']\n",
        "        SEP_TOKEN = SPECIAL_TOKENS['SEP']\n",
        "        \n",
        "        for i, j in zip(sentence_A_tokens, sentence_B_tokens):\n",
        "        \n",
        "            sentence = CLS_TOKEN + i + SEP_TOKEN + j + SEP_TOKEN\n",
        "            \n",
        "            token_ids = tokenizer.convert_tokens_to_ids(sentence)     \n",
        "            sentence_tokens.append(sentence)\n",
        "            \n",
        "            token_lengths.append(len(token_ids))      \n",
        "            input_ids.append(token_ids)\n",
        "        \n",
        "        return np.array(sentence_tokens), np.array(input_ids), np.array(token_lengths), np.array(processed_labels)\n",
        "    \n",
        "    def preprocess_dataset(self, d_partition=\"train_raw\"):\n",
        "    \n",
        "        print(f\"Preprocessing {d_partition} data\")\n",
        "        \n",
        "        if d_partition.lower() not in [\"train\", \"validation\", \"test\"]:\n",
        "            \n",
        "            raise BaseException(\n",
        "                \"d_partition must be train, validation or test\")\n",
        "        \n",
        "        if not os.path.exists(self.preprocessed_folder):\n",
        "            os.mkdir(self.preprocessed_folder)\n",
        "        \n",
        "        preprocessed_location = self.preprocessed_folder\n",
        "        file_name_base = os.path.join(preprocessed_folder, d_partition + \"_\")\n",
        "\n",
        "        \n",
        "        if os.path.exists(file_name_base + \"tokens.npy\"):           \n",
        "            print(\"Retrieving tokens from .npy files\")\n",
        "            \n",
        "            tokens = np.load(file_name_base + \"tokens.npy\", allow_pickle=True)\n",
        "            ids = np.load(file_name_base + \"token-ids.npy\", allow_pickle=True)\n",
        "            \n",
        "            lengths = np.load(file_name_base + \"token-lengths.npy\", allow_pickle=True)\n",
        "            labels = np.load(file_name_base + \"labels.npy\", allow_pickle=True)\n",
        "        \n",
        "        else:\n",
        "            if d_partition.lower() == \"train\":\n",
        "                dataset_df = self.train_raw\n",
        "            \n",
        "            elif d_partition.lower() == \"validation\":\n",
        "                dataset_df = self.eval_raw\n",
        "            \n",
        "            else:\n",
        "                dataset_df = self.test_raw\n",
        "            \n",
        "            tokens, ids, lengths, labels = self.preprocess_dataset_util(dataset_df)\n",
        "            \n",
        "            np.save(file_name_base + \"tokens.npy\", tokens)\n",
        "            np.save(file_name_base + \"token-ids.npy\", ids)\n",
        "            np.save(file_name_base + \"token-lengths.npy\", lengths)\n",
        "            np.save(file_name_base + \"labels.npy\", labels)\n",
        "        \n",
        "        print(f\"Saving preprocessed {d_partition} data\")\n",
        "        \n",
        "        return (tokens, ids, lengths, labels)\n",
        "    \n",
        "    def pad_and_create_attention_masks(self, input_ids):      \n",
        "        max_len_tokens = self.max_len_tokens       \n",
        "        if self.use_padding:\n",
        "            input_ids = pad_sequences(input_ids, maxlen=max_len_tokens, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "        \n",
        "        attention_masks = []       \n",
        "        for sentence in input_ids:\n",
        "            attention_mask = [int(token_id > 0) for token_id in sentence]\n",
        "            attention_masks.append(attention_mask)\n",
        "        \n",
        "        return input_ids, attention_masks\n",
        "    \n",
        "    def convert_data_to_tensor_dataset(self, tokens, attention_masks, labels):\n",
        "        \n",
        "        batch_size = self.batch_size \n",
        "\n",
        "        tokens = torch.tensor(tokens)       \n",
        "        attention_masks = torch.tensor(attention_masks)       \n",
        "        labels = torch.tensor(labels)   \n",
        "\n",
        "        data = TensorDataset(tokens, attention_masks, labels)\n",
        "        sampler = RandomSampler(data)        \n",
        "        dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
        "        \n",
        "        return (data, sampler, dataloader)\n",
        "    \n",
        "    def labels(self):\n",
        "        return self.dataset_labels"
      ],
      "metadata": {
        "id": "wWpnEII1_ZRY"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = SNLIDataset(tokenizer = tokenizer, \n",
        "                      dataset_folder = dataset_folder, \n",
        "                      preprocessed_folder = preprocessed_folder, \n",
        "                      batch_size = 32, \n",
        "                      max_len_tokens = 256, \n",
        "                      dataset_labels = DATASET_LABELS, \n",
        "                      download_dataset=False, \n",
        "                      use_padding=True)"
      ],
      "metadata": {
        "id": "3lp2a_Jy2M-4"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLCyBHBaRGPN"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens, train_input_ids, train_token_lenghts, train_labels = dataset.preprocess_dataset(d_partition=\"train\")\n",
        "validation_tokens, validation_input_ids, validation_token_lenghts, validation_labels = dataset.preprocess_dataset(d_partition=\"validation\")\n",
        "test_tokens, test_input_ids, test_token_lenghts, test_labels = dataset.preprocess_dataset(d_partition=\"test\")\n",
        "print(\"Padding inputs and creating attention masks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9E50AJ64LpP",
        "outputId": "fadb3696-15b8-435e-efc3-e3d9b2315302"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing train data\n",
            "Retrieving tokens from .npy files\n",
            "Saving preprocessed train data\n",
            "Preprocessing validation data\n",
            "Retrieving tokens from .npy files\n",
            "Saving preprocessed validation data\n",
            "Preprocessing test data\n",
            "Retrieving tokens from .npy files\n",
            "Saving preprocessed test data\n",
            "Padding inputs and creating attention masks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSAGnaH-RLUb"
      },
      "source": [
        "# Word embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids, train_attention_masks = dataset.pad_and_create_attention_masks(train_input_ids)\n",
        "\n",
        "validation_input_ids, validation_attention_masks = dataset.pad_and_create_attention_masks(validation_input_ids)\n",
        "\n",
        "test_input_ids, test_attention_masks = dataset.pad_and_create_attention_masks(test_input_ids)\n",
        "\n",
        "print(\"Converting dataset to PyTorch TensorDataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwi5_g-1Ea84",
        "outputId": "75d83b83-ba9e-48bf-cecb-81e7bdd8b6ec"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting dataset to PyTorch TensorDataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_sampler, train_dataloader = dataset.convert_data_to_tensor_dataset(train_input_ids, train_attention_masks, train_labels)\n",
        "\n",
        "validation_data, validation_sampler, validation_dataloader = dataset.convert_data_to_tensor_dataset(validation_input_ids, validation_attention_masks, validation_labels)\n",
        "\n",
        "test_data, test_sampler, test_dataloader = dataset.convert_data_to_tensor_dataset(test_input_ids, test_attention_masks, test_labels)"
      ],
      "metadata": {
        "id": "6raGu5QCEfW-"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zonPnO5NVZE"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1esLFFwDSjms"
      },
      "outputs": [],
      "source": [
        "class BERTModel:\n",
        "\n",
        "    def __init__(self, train_dataloader, num_labels, model_size, cased,\n",
        "                 output_attentions, output_hidden_states,\n",
        "                 optimizer, lr, eps, beta1, beta2,\n",
        "                 weight_decay, correct_bias, epochs):\n",
        "        \"\"\"\n",
        "            Args:\n",
        "            train_dataloder: (torch.utils.data.TensorDataset) Dataloder for the Training Set\n",
        "            num_labels: (int) Number of output labels\n",
        "            model_size: (str) Size of BERT Model [\"base\", \"large\"]\n",
        "            cased: (bool) Use cased or uncased BERT model\n",
        "            output_attentions: (bool) Output attention values from BERT Model\n",
        "            output_hidden_states: (bool) Output embeddings generated from BERT layers\n",
        "            optimizer: (str) Name of the Optimizer [\"AdamW\", \"AdamWeightDecay\"]\n",
        "            lr: (float) Learning Rate for the optimizer\n",
        "            eps: (float) Epsilon value for optimizer\n",
        "            beta1: (float) Beta1 value for Adam optimizer\n",
        "            beta2: (float) Beta2 value for Adam optimizer\n",
        "            weight_decay: (float) Weight Decay value for Adam optimizer\n",
        "            correct_bias: (float) Correct for bias terms in Adam Optimizer, default = True\n",
        "            epochs: (int) Number of epochs to run the model.\n",
        "        \"\"\"\n",
        "\n",
        "        self.num_labels = num_labels\n",
        "        self.model_size = model_size\n",
        "        self.cased = cased\n",
        "        self.output_attentions = output_attentions\n",
        "        self.output_hidden_states = output_hidden_states\n",
        "\n",
        "        self.lr = lr\n",
        "        self.eps = eps\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.weight_decay = weight_decay\n",
        "        self.correct_bias = correct_bias\n",
        "\n",
        "        self._train_dataloader = train_dataloader\n",
        "        self._epochs = epochs\n",
        "\n",
        "        cased_ = \"uncased\" if not cased else \"cased\"\n",
        "        model_name = f\"bert-{model_size}-{cased_}\"\n",
        "\n",
        "        model = BertForSequenceClassification.from_pretrained(\n",
        "                    model_name,\n",
        "                    num_labels=num_labels,\n",
        "                    output_attentions=output_attentions,\n",
        "                    output_hidden_states=output_hidden_states\n",
        "        )\n",
        "\n",
        "        if optimizer == \"AdamWeightDecay\":\n",
        "            optimizer = AdamWeightDecay(model.parameters(), learning_rate=lr, \n",
        "                                        beta_1=beta1, beta_2=beta2, epsilon=eps, weight_decay_rate=weight_decay)\n",
        "        else:\n",
        "            optimizer = AdamW(model.parameters(), lr=lr, eps=eps, \n",
        "                              betas=(beta1, beta2), weight_decay=weight_decay, correct_bias=correct_bias)\n",
        "\n",
        "        total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                    num_warmup_steps=0,\n",
        "                                                    num_training_steps=total_steps)\n",
        "\n",
        "        self._optimizer = optimizer\n",
        "        self._model = model\n",
        "        self._scheduler = scheduler\n",
        "\n",
        "    def model(self):\n",
        "        return self._model\n",
        "\n",
        "    def optimizer(self):\n",
        "        return self._optimizer\n",
        "\n",
        "    def scheduler(self):\n",
        "        return self._scheduler\n",
        "\n",
        "    def epochs(self):\n",
        "        return self._epochs\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self._train_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 4\n",
        "BATCH_SIZE = 32\n",
        "MODEL_PARAMS = {\n",
        "    'learning_rate': 2e-05,\n",
        "    'epsilon': 1e-08,\n",
        "    'beta1': 0.9,\n",
        "    'beta2': 0.999,\n",
        "    'weight_decay': 0.0,\n",
        "    'correct_bias': True\n",
        "}\n",
        "\n",
        "grad_clip_value = 1.0\n",
        "batch_print_freq = 200\n",
        "seed_value = 42\n",
        "\n",
        "DOWNLOAD_DATASET = False\n",
        "if SNLIDataset.download_dataset:\n",
        "    DOWNLOAD_DATASET = True\n",
        "\n",
        "MODEL_SIZE = \"base\"\n",
        "CASED = \"uncased\"\n",
        "\n",
        "num_labels = len(DATASET_LABELS)\n",
        "\n",
        "#USE_GPU = True\n",
        "#\n",
        "#RUN_PREDICTIONS = True\n",
        "#NO_TRAIN = True\n",
        "\n",
        "model_name = f\"bert-{MODEL_SIZE}-{CASED}\"\n",
        "\n",
        "BERTModel = BERTModel(\n",
        "      train_dataloader=train_dataloader,\n",
        "      num_labels = num_labels,\n",
        "      model_size = MODEL_SIZE,\n",
        "      cased = CASED,\n",
        "      output_attentions = True,\n",
        "      output_hidden_states = True,\n",
        "      optimizer = \"AdamW\",\n",
        "      lr = MODEL_PARAMS[\"learning_rate\"],\n",
        "      eps = MODEL_PARAMS[\"epsilon\"],\n",
        "      beta1 = MODEL_PARAMS[\"beta1\"],\n",
        "      beta2 = MODEL_PARAMS[\"beta2\"],\n",
        "      weight_decay = MODEL_PARAMS[\"weight_decay\"],\n",
        "      correct_bias = MODEL_PARAMS[\"correct_bias\"],\n",
        "      epochs=EPOCHS\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "91804bf5bb1e42b5ab5f1be1216190e8",
            "03ef6b5e96594b0f8aa92d6a045917d6",
            "19cdf3fb4f6943e3bd2b7032afe5c6a9",
            "7cfab5d27067465798097fc2428a2a1d",
            "47406f2b002f441bb6179d4a8e8b8df6",
            "0efad3a2828c4b5396c2456da7d591e7",
            "fabdad6913024f3aa0561ff44342029d",
            "4f96f79fb8b9453cb776d1b18e4d2f24",
            "771e3537a1d542b5a62c99b913b73caf",
            "0fa0286255a6445ea522bdbed0c6a6c3",
            "fc9161d65c81466b8357c334bd1dfdbf",
            "6cb5aee4317943e796cb4f24e6529c14",
            "f9e12ebbce5e48819bb3af078ef5e1b8",
            "283e9296b7424cad96aec294e7eea610",
            "fab46141aa6b47ab97c3b320d44af3c4",
            "be6cc8bee0ec41a3858dbcd4458e92d3",
            "cbdde9af1975438e9a941d505e9daeaa",
            "0100f7f304f542f58186ccbb038e0094",
            "f7e97640eadb4e048f9fb100e19ae395",
            "f61b8d33f8ed474fa85b46e64e19f3d3",
            "f7714111bb354ca88fc66e91f9bd571b",
            "572367eed5c344f7a95b7eee093ebb4f"
          ]
        },
        "id": "AQ_TXqfeHhIH",
        "outputId": "b0f688a0-95bc-42c0-9a0c-3236081783e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91804bf5bb1e42b5ab5f1be1216190e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cb5aee4317943e796cb4f24e6529c14"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zui9TpZZRWYN"
      },
      "source": [
        "# Training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "lQm_bxyEVyAt"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round(elapsed))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "7vaofW6Hhjdr"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "TLQBIoq6SX2M"
      },
      "outputs": [],
      "source": [
        "# Train and evaluation\n",
        "def train_and_evaluate_bert(BERTModel, validation_dataloader, use_gpu, seed_value, batch_print_freq, grad_clip_value):\n",
        "    \"\"\"\n",
        "    Train the BERT Model\n",
        "    Args:\n",
        "        BERTModel: (models.bert) Object of BERTModel class, containing model, optimizer and scheduler\n",
        "        validation_dataloder: (torch.utils.data.TensorDataset) Dataloder for the Validation Set\n",
        "        use_gpu: (bool) Use GPU if available for training\n",
        "        seed_value: (int) Seed Value for random number generation\n",
        "        batch_print_freq: (int) Number of batches after which info is logged\n",
        "        grad_clip_value: (float) Max value of gradient, higher gradients are clipped to this value\n",
        "    \"\"\"\n",
        "\n",
        "    if use_gpu and torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"There are {torch.cuda.device_count()} GPU(s) available\")\n",
        "        print(f\"Using {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"Using CPU\")\n",
        "\n",
        "    model = BERTModel.model()\n",
        "    optimizer = BERTModel.optimizer()\n",
        "    scheduler = BERTModel.scheduler()\n",
        "    epochs = BERTModel.epochs()\n",
        "    train_dataloader = BERTModel.train_dataloader()\n",
        "\n",
        "    print(\"Model, Optimizer and Scheduler setup successfully!\")\n",
        "\n",
        "    if use_gpu:\n",
        "        model.cuda()\n",
        "\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    if use_gpu:\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "    loss_values = []\n",
        "    metrics = []\n",
        "\n",
        "    print(\"Training started\")\n",
        "\n",
        "    t = range(epochs)\n",
        "    for epoch in t:\n",
        "        epMetric = {}\n",
        "        print(f\"Epoch {epoch + 1} / {epochs}\")\n",
        "        epMetric[\"epoch\"] = epoch + 1\n",
        "        start_time = time.time()\n",
        "        total_loss = 0\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            if step % batch_print_freq == 0 and not step == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                time_per_batch = elapsed / step\n",
        "                time_remaining = (len(train_dataloader) -\n",
        "                                  step) * time_per_batch\n",
        "                print(f\"\\nBatch {step} of {len(train_dataloader)}. Elapsed: {format_time(elapsed)}\")\n",
        "                print(f\"Time left in this epoch: {format_time(time_remaining)}\")\n",
        "\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            output = model(b_input_ids,\n",
        "                           token_type_ids=None,\n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels)\n",
        "\n",
        "            loss = output[0]\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_value)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        loss_values.append(avg_train_loss)\n",
        "\n",
        "        p_time = time.time()\n",
        "        time_taken_train = format_time(p_time - start_time)\n",
        "\n",
        "        epMetric[\"time_taken_train\"] = time_taken_train\n",
        "        epMetric[\"epoch_avg_loss\"] = avg_train_loss\n",
        "\n",
        "        print(f\"\\n Average Training Loss: {avg_train_loss} \")\n",
        "        print(f\"Training Epoch Time: {time_taken_train} \\n\")\n",
        "\n",
        "        print(\"Validation\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        model.eval()\n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        nb_eval_steps = 0\n",
        "\n",
        "        for batch in validation_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(b_input_ids,\n",
        "                                token_type_ids=None,\n",
        "                                attention_mask=b_input_mask)\n",
        "\n",
        "            logits = outputs[0]\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "        p_time = time.time()\n",
        "        time_taken_validation = format_time(p_time - start_time)\n",
        "        validation_accuracy = eval_accuracy / nb_eval_steps\n",
        "\n",
        "        epMetric[\"time_taken_validation\"] = time_taken_validation\n",
        "        epMetric[\"validation_accuracy\"] = validation_accuracy\n",
        "\n",
        "        print(f\"Accuracy: {validation_accuracy}\")\n",
        "        print(f\"Validation Took: {time_taken_validation}\")\n",
        "\n",
        "        metrics.append(epMetric)\n",
        "\n",
        "    print(\"Training Complete\")\n",
        "\n",
        "    return (model, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_from_file(saved_model_location):\n",
        "\n",
        "    model_weight_dir = saved_model_location\n",
        "\n",
        "    if not os.path.exists(model_weight_dir):\n",
        "        raise Exception(f\"Directory {saved_model_location} doesn't exist\")\n",
        "\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        model_weight_dir,\n",
        "        output_hidden_states=True\n",
        "    )\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_weight_dir)\n",
        "\n",
        "    print(f\"Loaded pretrained model and tokenizer from {model_weight_dir}\")\n",
        "\n",
        "    return (model, tokenizer)\n",
        "\n",
        "\n",
        "def run_model_on_test_set(test_dataloader, saved_model_location, use_gpu, batch_print_freq):\n",
        "\n",
        "    if use_gpu and torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"There are {torch.cuda.device_count()} GPU(s) available\")\n",
        "        print(f\"Using {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"Using CPU\")\n",
        "\n",
        "    model, _ = load_model_from_file(saved_model_location)\n",
        "    model.cuda()\n",
        "\n",
        "    predictions, true_labels = [], []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "\n",
        "      #batch = tuple(t.to(device) for t in batch)\n",
        "      #b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "      with torch.no_grad():\n",
        "            outputs = model(b_input_ids, token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "            logits = outputs[0]\n",
        "\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.detach().cpu().numpy()\n",
        "\n",
        "            predictions.append(logits)\n",
        "            true_labels.append(label_ids)\n",
        "\n",
        "            predictions = np.concatenate(predictions, axis=0)\n",
        "            true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "      print('Done with Predictions!')\n",
        "\n",
        "      return (predictions, true_labels)"
      ],
      "metadata": {
        "id": "VaCYeOnagjX4"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_on_test_set(test_dataloader, dataset_labels,\n",
        "                               saved_model_location, use_gpu, batch_print_freq\n",
        "                               ):\n",
        "\n",
        "    predictions, true_labels = run_model_on_test_set(\n",
        "        test_dataloader=test_dataloader,\n",
        "        saved_model_location=saved_model_location,\n",
        "        use_gpu=use_gpu,\n",
        "        batch_print_freq=batch_print_freq\n",
        "    )\n",
        "    pred_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "    exact_match_score = accuracy_score(true_labels, pred_labels)\n",
        "    hamming_score = hamming_loss(true_labels, pred_labels)\n",
        "\n",
        "    labels = list(dataset_labels.values())\n",
        "    target_names = list(dataset_labels.keys())\n",
        "\n",
        "    prec_recall_report = classification_report(true_labels, pred_labels, labels=labels, target_names=target_names, output_dict=True)\n",
        "\n",
        "    evaluation = {}\n",
        "    evaluation[\"exact_march_score\"] = exact_match_score\n",
        "    evaluation[\"hamming_score\"] = hamming_score\n",
        "    evaluation[\"prec_recall_report\"] = prec_recall_report\n",
        "\n",
        "    cf_matrix = confusion_matrix(true_labels, pred_labels)\n",
        "    matrix = sns.heatmap(cf_matrix, annot=True)\n",
        "    matrix.xaxis.set_ticks_position('top') \n",
        "    matrix.set(xlabel='prediction', ylabel='Gold label')\n",
        "    plt.title('Confusion Matrix\\n0=Neutral, 1=Entailment, 2=Contradiction')\n",
        "    plt.show()\n",
        "\n",
        "    print(cf_matrix)\n",
        "\n",
        "    return evaluation"
      ],
      "metadata": {
        "id": "P3binmhYR703"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, metrics = train_and_evaluate_bert(\n",
        "    BERTModel=BERTModel,\n",
        "    validation_dataloader=validation_dataloader,\n",
        "    use_gpu = True,\n",
        "    seed_value = seed_value,\n",
        "    batch_print_freq=batch_print_freq,\n",
        "    grad_clip_value=grad_clip_value\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYpFWgBHGazv",
        "outputId": "b8c0708f-83df-4fb0-cc09-59a6d4b53b44"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available\n",
            "Using A100-SXM4-40GB\n",
            "Model, Optimizer and Scheduler setup successfully!\n",
            "Training started\n",
            "Epoch 1 / 4\n",
            "\n",
            "Batch 200 of 3434. Elapsed: 0:01:07\n",
            "Time left in this epoch: 0:18:03\n",
            "\n",
            "Batch 400 of 3434. Elapsed: 0:02:14\n",
            "Time left in this epoch: 0:16:54\n",
            "\n",
            "Batch 600 of 3434. Elapsed: 0:03:21\n",
            "Time left in this epoch: 0:15:47\n",
            "\n",
            "Batch 800 of 3434. Elapsed: 0:04:27\n",
            "Time left in this epoch: 0:14:40\n",
            "\n",
            "Batch 1000 of 3434. Elapsed: 0:05:34\n",
            "Time left in this epoch: 0:13:33\n",
            "\n",
            "Batch 1200 of 3434. Elapsed: 0:06:41\n",
            "Time left in this epoch: 0:12:26\n",
            "\n",
            "Batch 1400 of 3434. Elapsed: 0:07:48\n",
            "Time left in this epoch: 0:11:19\n",
            "\n",
            "Batch 1600 of 3434. Elapsed: 0:08:54\n",
            "Time left in this epoch: 0:10:13\n",
            "\n",
            "Batch 1800 of 3434. Elapsed: 0:10:01\n",
            "Time left in this epoch: 0:09:06\n",
            "\n",
            "Batch 2000 of 3434. Elapsed: 0:11:08\n",
            "Time left in this epoch: 0:07:59\n",
            "\n",
            "Batch 2200 of 3434. Elapsed: 0:12:15\n",
            "Time left in this epoch: 0:06:52\n",
            "\n",
            "Batch 2400 of 3434. Elapsed: 0:13:21\n",
            "Time left in this epoch: 0:05:45\n",
            "\n",
            "Batch 2600 of 3434. Elapsed: 0:14:28\n",
            "Time left in this epoch: 0:04:39\n",
            "\n",
            "Batch 2800 of 3434. Elapsed: 0:15:35\n",
            "Time left in this epoch: 0:03:32\n",
            "\n",
            "Batch 3000 of 3434. Elapsed: 0:16:42\n",
            "Time left in this epoch: 0:02:25\n",
            "\n",
            "Batch 3200 of 3434. Elapsed: 0:17:49\n",
            "Time left in this epoch: 0:01:18\n",
            "\n",
            "Batch 3400 of 3434. Elapsed: 0:18:55\n",
            "Time left in this epoch: 0:00:11\n",
            "\n",
            " Average Training Loss: 0.10243028609557256 \n",
            "Training Epoch Time: 0:19:07 \n",
            "\n",
            "Validation\n",
            "Accuracy: 0.8735119047619048\n",
            "Validation Took: 0:00:06\n",
            "Epoch 2 / 4\n",
            "\n",
            "Batch 200 of 3434. Elapsed: 0:01:07\n",
            "Time left in this epoch: 0:18:00\n",
            "\n",
            "Batch 400 of 3434. Elapsed: 0:02:14\n",
            "Time left in this epoch: 0:16:53\n",
            "\n",
            "Batch 600 of 3434. Elapsed: 0:03:20\n",
            "Time left in this epoch: 0:15:46\n",
            "\n",
            "Batch 800 of 3434. Elapsed: 0:04:27\n",
            "Time left in this epoch: 0:14:40\n",
            "\n",
            "Batch 1000 of 3434. Elapsed: 0:05:34\n",
            "Time left in this epoch: 0:13:33\n",
            "\n",
            "Batch 1200 of 3434. Elapsed: 0:06:41\n",
            "Time left in this epoch: 0:12:26\n",
            "\n",
            "Batch 1400 of 3434. Elapsed: 0:07:48\n",
            "Time left in this epoch: 0:11:19\n",
            "\n",
            "Batch 1600 of 3434. Elapsed: 0:08:54\n",
            "Time left in this epoch: 0:10:12\n",
            "\n",
            "Batch 1800 of 3434. Elapsed: 0:10:01\n",
            "Time left in this epoch: 0:09:06\n",
            "\n",
            "Batch 2000 of 3434. Elapsed: 0:11:08\n",
            "Time left in this epoch: 0:07:59\n",
            "\n",
            "Batch 2200 of 3434. Elapsed: 0:12:15\n",
            "Time left in this epoch: 0:06:52\n",
            "\n",
            "Batch 2400 of 3434. Elapsed: 0:13:21\n",
            "Time left in this epoch: 0:05:45\n",
            "\n",
            "Batch 2600 of 3434. Elapsed: 0:14:28\n",
            "Time left in this epoch: 0:04:38\n",
            "\n",
            "Batch 2800 of 3434. Elapsed: 0:15:35\n",
            "Time left in this epoch: 0:03:32\n",
            "\n",
            "Batch 3000 of 3434. Elapsed: 0:16:42\n",
            "Time left in this epoch: 0:02:25\n",
            "\n",
            "Batch 3200 of 3434. Elapsed: 0:17:48\n",
            "Time left in this epoch: 0:01:18\n",
            "\n",
            "Batch 3400 of 3434. Elapsed: 0:18:55\n",
            "Time left in this epoch: 0:00:11\n",
            "\n",
            " Average Training Loss: 0.08482998905944257 \n",
            "Training Epoch Time: 0:19:07 \n",
            "\n",
            "Validation\n",
            "Accuracy: 0.8730742296918766\n",
            "Validation Took: 0:00:06\n",
            "Epoch 3 / 4\n",
            "\n",
            "Batch 200 of 3434. Elapsed: 0:01:07\n",
            "Time left in this epoch: 0:18:00\n",
            "\n",
            "Batch 400 of 3434. Elapsed: 0:02:14\n",
            "Time left in this epoch: 0:16:53\n",
            "\n",
            "Batch 600 of 3434. Elapsed: 0:03:20\n",
            "Time left in this epoch: 0:15:46\n",
            "\n",
            "Batch 800 of 3434. Elapsed: 0:04:27\n",
            "Time left in this epoch: 0:14:39\n",
            "\n",
            "Batch 1000 of 3434. Elapsed: 0:05:34\n",
            "Time left in this epoch: 0:13:33\n",
            "\n",
            "Batch 1200 of 3434. Elapsed: 0:06:41\n",
            "Time left in this epoch: 0:12:26\n",
            "\n",
            "Batch 1400 of 3434. Elapsed: 0:07:47\n",
            "Time left in this epoch: 0:11:19\n",
            "\n",
            "Batch 1600 of 3434. Elapsed: 0:08:54\n",
            "Time left in this epoch: 0:10:12\n",
            "\n",
            "Batch 1800 of 3434. Elapsed: 0:10:01\n",
            "Time left in this epoch: 0:09:06\n",
            "\n",
            "Batch 2000 of 3434. Elapsed: 0:11:08\n",
            "Time left in this epoch: 0:07:59\n",
            "\n",
            "Batch 2200 of 3434. Elapsed: 0:12:15\n",
            "Time left in this epoch: 0:06:52\n",
            "\n",
            "Batch 2400 of 3434. Elapsed: 0:13:21\n",
            "Time left in this epoch: 0:05:45\n",
            "\n",
            "Batch 2600 of 3434. Elapsed: 0:14:28\n",
            "Time left in this epoch: 0:04:38\n",
            "\n",
            "Batch 2800 of 3434. Elapsed: 0:15:35\n",
            "Time left in this epoch: 0:03:32\n",
            "\n",
            "Batch 3000 of 3434. Elapsed: 0:16:42\n",
            "Time left in this epoch: 0:02:25\n",
            "\n",
            "Batch 3200 of 3434. Elapsed: 0:17:49\n",
            "Time left in this epoch: 0:01:18\n",
            "\n",
            "Batch 3400 of 3434. Elapsed: 0:18:55\n",
            "Time left in this epoch: 0:00:11\n",
            "\n",
            " Average Training Loss: 0.08357371076581871 \n",
            "Training Epoch Time: 0:19:07 \n",
            "\n",
            "Validation\n",
            "Accuracy: 0.8721988795518206\n",
            "Validation Took: 0:00:06\n",
            "Epoch 4 / 4\n",
            "\n",
            "Batch 200 of 3434. Elapsed: 0:01:07\n",
            "Time left in this epoch: 0:18:00\n",
            "\n",
            "Batch 400 of 3434. Elapsed: 0:02:14\n",
            "Time left in this epoch: 0:16:53\n",
            "\n",
            "Batch 600 of 3434. Elapsed: 0:03:20\n",
            "Time left in this epoch: 0:15:46\n",
            "\n",
            "Batch 800 of 3434. Elapsed: 0:04:27\n",
            "Time left in this epoch: 0:14:40\n",
            "\n",
            "Batch 1000 of 3434. Elapsed: 0:05:34\n",
            "Time left in this epoch: 0:13:33\n",
            "\n",
            "Batch 1200 of 3434. Elapsed: 0:06:41\n",
            "Time left in this epoch: 0:12:26\n",
            "\n",
            "Batch 1400 of 3434. Elapsed: 0:07:47\n",
            "Time left in this epoch: 0:11:19\n",
            "\n",
            "Batch 1600 of 3434. Elapsed: 0:08:54\n",
            "Time left in this epoch: 0:10:12\n",
            "\n",
            "Batch 1800 of 3434. Elapsed: 0:10:01\n",
            "Time left in this epoch: 0:09:06\n",
            "\n",
            "Batch 2000 of 3434. Elapsed: 0:11:08\n",
            "Time left in this epoch: 0:07:59\n",
            "\n",
            "Batch 2200 of 3434. Elapsed: 0:12:15\n",
            "Time left in this epoch: 0:06:52\n",
            "\n",
            "Batch 2400 of 3434. Elapsed: 0:13:21\n",
            "Time left in this epoch: 0:05:45\n",
            "\n",
            "Batch 2600 of 3434. Elapsed: 0:14:28\n",
            "Time left in this epoch: 0:04:39\n",
            "\n",
            "Batch 2800 of 3434. Elapsed: 0:15:35\n",
            "Time left in this epoch: 0:03:32\n",
            "\n",
            "Batch 3000 of 3434. Elapsed: 0:16:42\n",
            "Time left in this epoch: 0:02:25\n",
            "\n",
            "Batch 3200 of 3434. Elapsed: 0:17:49\n",
            "Time left in this epoch: 0:01:18\n",
            "\n",
            "Batch 3400 of 3434. Elapsed: 0:18:55\n",
            "Time left in this epoch: 0:00:11\n",
            "\n",
            " Average Training Loss: 0.1040567363414102 \n",
            "Training Epoch Time: 0:19:07 \n",
            "\n",
            "Validation\n",
            "Accuracy: 0.8721988795518206\n",
            "Validation Took: 0:00:06\n",
            "Training Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = saved_model_location\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(f\"Saving model to {output_dir}\")\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "with open(os.path.join(output_dir, \"model-metrics.json\"), \"w\") as f:\n",
        "    model_metrics = json.dumps(metrics)\n",
        "    f.write(model_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcP34CV_nfIT",
        "outputId": "7b7ebbfb-06ab-44a6-f82e-780bb24a7f75"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to saved_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIUnsBt0SoyV"
      },
      "source": [
        "# Prediction and model performance checking"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing = evaluate_model_on_test_set(\n",
        "    test_dataloader=test_dataloader,\n",
        "    dataset_labels=dataset_labels,\n",
        "    saved_model_location=saved_model_location,\n",
        "    use_gpu = True,\n",
        "    batch_print_freq=batch_print_freq\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "XviYooVBH-Xz",
        "outputId": "a282419c-8916-41da-b4e8-076db6ad35a9"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available\n",
            "Using A100-SXM4-40GB\n",
            "Loaded pretrained model and tokenizer from saved_models\n",
            "Done with Predictions!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5  1  1]\n",
            " [ 0  9  2]\n",
            " [ 0  0 14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(saved_model_location + \"model-evaluation.json\", \"w\") as f:\n",
        "        output = json.dumps(testing)\n",
        "        f.write(output)"
      ],
      "metadata": {
        "id": "G1UIpjo8J9L8"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "54ZMyZxrMYMp",
        "outputId": "a935318e-3a61-48d4-8520-4654c6c03c5b"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"exact_march_score\": 0.875, \"hamming_score\": 0.125, \"prec_recall_report\": {\"contradiction\": {\"precision\": 1.0, \"recall\": 0.7142857142857143, \"f1-score\": 0.8333333333333333, \"support\": 7}, \"entailment\": {\"precision\": 0.9, \"recall\": 0.8181818181818182, \"f1-score\": 0.8571428571428572, \"support\": 11}, \"neutral\": {\"precision\": 0.8235294117647058, \"recall\": 1.0, \"f1-score\": 0.9032258064516129, \"support\": 14}, \"accuracy\": 0.875, \"macro avg\": {\"precision\": 0.907843137254902, \"recall\": 0.8441558441558442, \"f1-score\": 0.8645673323092677, \"support\": 32}, \"weighted avg\": {\"precision\": 0.8884191176470588, \"recall\": 0.875, \"f1-score\": 0.8720958141321045, \"support\": 32}}}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z_h31bOSi7T"
      },
      "outputs": [],
      "source": [
        "## Plot loss\n",
        "#plt.plot(list(range(1, max_epoch+1)), train_loss_, color='red', marker='o')\n",
        "#plt.plot(list(range(1, max_epoch+1)), eval_loss_, color='green', marker='^')\n",
        "#plt.gca().get_xaxis().set_major_locator(ticker.MaxNLocator(integer=True))\n",
        "#plt.title('Model loss\\nEpoch = ' + str(max_epoch))\n",
        "#plt.legend(['Train loss', 'Evaluation loss'])\n",
        "#plt.xlabel('Epoch')\n",
        "#plt.ylabel('Average cross entropy loss')\n",
        "#plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEIHXI/Yf7eUhykd/NkW9H",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f55f4d7b3113497f825d5d31b11510b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96a13aeaca894fb68ca07642d53536a4",
              "IPY_MODEL_1b06068469124dda909d68e228446f0a",
              "IPY_MODEL_0128d9e03daf4b0fb886da8c4be4ce68"
            ],
            "layout": "IPY_MODEL_48ffaf79c5a945cf8e1297407fc9cc88"
          }
        },
        "96a13aeaca894fb68ca07642d53536a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a61e3057fa1d440fae4b85a361867efb",
            "placeholder": "​",
            "style": "IPY_MODEL_0b511fcf2e1a4dc8b92902198a644bc9",
            "value": "Downloading: 100%"
          }
        },
        "1b06068469124dda909d68e228446f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_019988eb70554cf4b3577ee3adf92dc4",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70c1643f8ba9432ea00e3351332b869c",
            "value": 213450
          }
        },
        "0128d9e03daf4b0fb886da8c4be4ce68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19b2ebb0ac544c07bdf2a26d7b3afe0f",
            "placeholder": "​",
            "style": "IPY_MODEL_81721714b478482da37d98ca053a3348",
            "value": " 213k/213k [00:00&lt;00:00, 2.08MB/s]"
          }
        },
        "48ffaf79c5a945cf8e1297407fc9cc88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a61e3057fa1d440fae4b85a361867efb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b511fcf2e1a4dc8b92902198a644bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "019988eb70554cf4b3577ee3adf92dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70c1643f8ba9432ea00e3351332b869c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19b2ebb0ac544c07bdf2a26d7b3afe0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81721714b478482da37d98ca053a3348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91804bf5bb1e42b5ab5f1be1216190e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03ef6b5e96594b0f8aa92d6a045917d6",
              "IPY_MODEL_19cdf3fb4f6943e3bd2b7032afe5c6a9",
              "IPY_MODEL_7cfab5d27067465798097fc2428a2a1d"
            ],
            "layout": "IPY_MODEL_47406f2b002f441bb6179d4a8e8b8df6"
          }
        },
        "03ef6b5e96594b0f8aa92d6a045917d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0efad3a2828c4b5396c2456da7d591e7",
            "placeholder": "​",
            "style": "IPY_MODEL_fabdad6913024f3aa0561ff44342029d",
            "value": "Downloading: 100%"
          }
        },
        "19cdf3fb4f6943e3bd2b7032afe5c6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f96f79fb8b9453cb776d1b18e4d2f24",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_771e3537a1d542b5a62c99b913b73caf",
            "value": 433
          }
        },
        "7cfab5d27067465798097fc2428a2a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fa0286255a6445ea522bdbed0c6a6c3",
            "placeholder": "​",
            "style": "IPY_MODEL_fc9161d65c81466b8357c334bd1dfdbf",
            "value": " 433/433 [00:00&lt;00:00, 32.3kB/s]"
          }
        },
        "47406f2b002f441bb6179d4a8e8b8df6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0efad3a2828c4b5396c2456da7d591e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fabdad6913024f3aa0561ff44342029d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f96f79fb8b9453cb776d1b18e4d2f24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "771e3537a1d542b5a62c99b913b73caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fa0286255a6445ea522bdbed0c6a6c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc9161d65c81466b8357c334bd1dfdbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cb5aee4317943e796cb4f24e6529c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9e12ebbce5e48819bb3af078ef5e1b8",
              "IPY_MODEL_283e9296b7424cad96aec294e7eea610",
              "IPY_MODEL_fab46141aa6b47ab97c3b320d44af3c4"
            ],
            "layout": "IPY_MODEL_be6cc8bee0ec41a3858dbcd4458e92d3"
          }
        },
        "f9e12ebbce5e48819bb3af078ef5e1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbdde9af1975438e9a941d505e9daeaa",
            "placeholder": "​",
            "style": "IPY_MODEL_0100f7f304f542f58186ccbb038e0094",
            "value": "Downloading: 100%"
          }
        },
        "283e9296b7424cad96aec294e7eea610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7e97640eadb4e048f9fb100e19ae395",
            "max": 435779157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f61b8d33f8ed474fa85b46e64e19f3d3",
            "value": 435779157
          }
        },
        "fab46141aa6b47ab97c3b320d44af3c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7714111bb354ca88fc66e91f9bd571b",
            "placeholder": "​",
            "style": "IPY_MODEL_572367eed5c344f7a95b7eee093ebb4f",
            "value": " 436M/436M [00:09&lt;00:00, 54.8MB/s]"
          }
        },
        "be6cc8bee0ec41a3858dbcd4458e92d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbdde9af1975438e9a941d505e9daeaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0100f7f304f542f58186ccbb038e0094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7e97640eadb4e048f9fb100e19ae395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f61b8d33f8ed474fa85b46e64e19f3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7714111bb354ca88fc66e91f9bd571b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "572367eed5c344f7a95b7eee093ebb4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}