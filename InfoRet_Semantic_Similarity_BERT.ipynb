{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNucHLjh0ojg+xdZLqGabkN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzrossi/InfoRet_SemanticSimilarity/blob/main/InfoRet_Semantic_Similarity_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import opendatasets as op\n",
        "\n",
        "import os\n",
        "\n",
        "# NLTK\n",
        "import nltk as nlp\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import ngrams\n",
        "\n",
        "# PYTORCH\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig\n",
        "import random\n",
        "import gc\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dir = '/content/drive/MyDrive/Infor'"
      ],
      "metadata": {
        "id": "ICord5RYWE9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets LORENZO TU DEVI CARICARE I FILE DA DRIVE STUPIDO COGLIONE\n",
        "\n",
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "op.download(\"https://www.kaggle.com/datasets/stanfordu/stanford-natural-language-inference-corpus\")"
      ],
      "metadata": {
        "id": "3Q12KZ2lWFrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.download('stopwords')\n",
        "stop_words = stopwords.words('english')"
      ],
      "metadata": {
        "id": "bLFhrnBFUeRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasetFolder = \"mettere folder drive\""
      ],
      "metadata": {
        "id": "oGQgtVrdUTw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw = pd.read_csv(os.path.join(datasetFolder, \"snli_1.0_train.csv\"))\n",
        "test_raw = pd.read_csv(os.path.join(datasetFolder, \"snli_1.0_test.csv\"))\n",
        "eval_raw = pd.read_csv(os.path.join(datasetFolder, \"snli_1.0_dev.csv\"))"
      ],
      "metadata": {
        "id": "Ggx6Z93sUmMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw.head(3)"
      ],
      "metadata": {
        "id": "JVz11TiyLjY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw.describe()"
      ],
      "metadata": {
        "id": "8vlM6ubCLmeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_raw.describe()"
      ],
      "metadata": {
        "id": "iiSViaoSL7Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_raw.describe()"
      ],
      "metadata": {
        "id": "sbYawflJMCrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data shape and missing values\n",
        "print('■ Train set: ' + str(train_raw.shape))\n",
        "print(train_raw.isnull().sum())\n",
        "\n",
        "print('\\n■ Evaluation set: ' + str(eval_raw.shape))\n",
        "print(eval_raw.isnull().sum())\n",
        "\n",
        "print('\\n■ Test set:' + str(test_raw.shape))\n",
        "print(test_raw.isnull().sum())"
      ],
      "metadata": {
        "id": "pqLv1LJRMGE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure all datasets have the same labels\n",
        "print(train_raw['gold_label'].unique())\n",
        "print(eval_raw['gold_label'].unique())\n",
        "print(test_raw['gold_label'].unique())"
      ],
      "metadata": {
        "id": "gwPvXrcMMGqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Propotion of gold labels (train only)\n",
        "ratio_gold = train_raw['gold_label'].value_counts(normalize=True).sort_index(ascending=False).reset_index().set_index('index')\n",
        "ratio_gold['gold_label'] = ratio_gold['gold_label'].apply(lambda x: round(x, 3))\n",
        "ratio_gold"
      ],
      "metadata": {
        "id": "KWjia1wtMKC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the propotion\n",
        "colors = sns.color_palette('pastel')\n",
        "plt.pie(ratio_gold['gold_label'], labels=ratio_gold.index, colors=colors, autopct='%.1f%%', startangle=90)\n",
        "plt.title('Proportion of the gold labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hJhCKUZZMQ0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lengths of sentenses (train only)\n",
        "# Sentense 1\n",
        "train_sent1 = train_raw['sentence1'].str.count(' ') + 1\n",
        "train_sent1 = train_sent1.apply(lambda x: int(x))\n",
        "print('Sentence 1\\n', round(train_sent1.describe(), 2))\n",
        "\n",
        "# Sentense 2\n",
        "train_sent2 = train_raw['sentence2'].dropna().str.count(' ') + 1\n",
        "train_sent2 = train_sent2.apply(lambda x: int(x))\n",
        "print('\\nSentence 2\\n', round(train_sent2.describe(), 2))"
      ],
      "metadata": {
        "id": "uXKazwc-MStu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the distribution of the lengths of sentences 1 and 2\n",
        "train_sentences = pd.DataFrame({'sentence1':train_sent1,\n",
        "                                'sentence2':train_sent2})\n",
        "\n",
        "box = sns.boxplot(data=train_sentences, palette=colors)\n",
        "box.set_ylabel('Words in a sentence')\n",
        "box.set_title('Distribution of the lengths of sentences')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FS0kWd6YMWD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examples in sentence 1\n",
        "# Minimum count of words\n",
        "example1_min = train_sent1[train_sent1 == train_sent1.min()].sample(1)\n",
        "print('Min word count: ', train_sent1.min())\n",
        "print('Example: ', train_raw['sentence1'].loc[example1_min.index])\n",
        "print('\\n')\n",
        "\n",
        "# Maximum count of words\n",
        "example1_max = train_sent1[train_sent1 == train_sent1.max()].sample(1)\n",
        "print('Max word count: ', train_sent1.max())\n",
        "print('Example: ', train_raw['sentence1'].loc[example1_max.index])"
      ],
      "metadata": {
        "id": "joqeihq6Metn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examples in sentence 2\n",
        "# Minimum count of words\n",
        "example2_min = train_sent2[train_sent2 == train_sent2.min()].sample(1)\n",
        "print('Min word count: ', train_sent2.min())\n",
        "print('Example: ', train_raw['sentence2'].loc[example2_min.index])\n",
        "print('\\n')\n",
        "\n",
        "# Maximum count of words\n",
        "example2_max = train_sent2[train_sent2 == train_sent2.max()].sample(1)\n",
        "print('Max word count: ', train_sent2.max())\n",
        "print('Example: ', train_raw['sentence2'].loc[example2_max.index])"
      ],
      "metadata": {
        "id": "hKj6TbJyMhFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPROCESSING"
      ],
      "metadata": {
        "id": "Nf-Jmdc7MjBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Omit rows having the gold label \"-\" and irrelevant columns \n",
        "train = train_raw[['gold_label', 'sentence1', 'sentence2']][train_raw['gold_label'] != '-'].set_index(train_raw['pairID'][train_raw['gold_label'] != '-'])\n",
        "eval = eval_raw[['gold_label', 'sentence1', 'sentence2']][eval_raw['gold_label'] != '-'].set_index(eval_raw['pairID'][eval_raw['gold_label'] != '-'])\n",
        "test = test_raw[['gold_label', 'sentence1', 'sentence2']][test_raw['gold_label'] != '-'].set_index(test_raw['pairID'][test_raw['gold_label'] != '-'])\n",
        "\n",
        "# Minimize the datasets for quick trials\n",
        "train = train.iloc[:50000, :]\n",
        "eval = eval.sample(100)\n",
        "test = test.sample(100)\n",
        "\n",
        "train.head(3)"
      ],
      "metadata": {
        "id": "4kPe3yofMmcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Omit null indexes\n",
        "train.dropna(subset=['sentence2'], inplace=True)\n",
        "\n",
        "# Recheck the number of null values\n",
        "print(train.isnull().sum())\n",
        "print(eval.isnull().sum())\n",
        "print(test.isnull().sum())"
      ],
      "metadata": {
        "id": "PreogCY7Mpv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check sentences including URL\n",
        "print(train['sentence1'][train['sentence1'].str.contains('http')].count())\n",
        "print(train['sentence2'][train['sentence2'].str.contains('http')].count())\n",
        "\n",
        "print(eval['sentence1'][eval['sentence1'].str.contains('http')].count())\n",
        "print(eval['sentence2'][eval['sentence2'].str.contains('http')].count())\n",
        "\n",
        "print(test['sentence1'][test['sentence1'].str.contains('http')].count())\n",
        "print(test['sentence2'][test['sentence2'].str.contains('http')].count())"
      ],
      "metadata": {
        "id": "2rU229NgMr5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check URL-only sentences\n",
        "dropindex = train.index[train['sentence2'].str.contains('http')]\n",
        "train[train['sentence2'].str.contains('http')]"
      ],
      "metadata": {
        "id": "5s0P4fpWMunx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Omit URL-only sentences\n",
        "train.drop(index=dropindex, inplace=True)\n",
        "print(train[train['sentence2'].str.contains('http')].count())"
      ],
      "metadata": {
        "id": "_hoEzj9lMvLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy coding for gold labels\n",
        "train['gold_label'] = train['gold_label'].replace('neutral', 0).replace('entailment', 1).replace('contradiction', 2)\n",
        "eval['gold_label'] = eval['gold_label'].replace('neutral', 0).replace('entailment', 1).replace('contradiction', 2)\n",
        "test['gold_label'] = test['gold_label'].replace('neutral', 0).replace('entailment', 1).replace('contradiction', 2)\n",
        "\n",
        "train.head(3)"
      ],
      "metadata": {
        "id": "cZ_1rReEMw6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frequency analysis"
      ],
      "metadata": {
        "id": "YCh9TGEoNJ7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.download('popular')"
      ],
      "metadata": {
        "id": "zFbvbNCENExN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentence):\n",
        "    # Tokenization\n",
        "    new_tokens = word_tokenize(sentence)\n",
        "    new_tokens = [t.lower() for t in new_tokens]\n",
        "    new_tokens = [t for t in new_tokens if t not in stopwords.words('english')]\n",
        "    new_tokens = [t for t in new_tokens if t.isalpha()]\n",
        "\n",
        "    # Lemmatization (become, becomes, becoming, became --> become)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    new_tokens =[lemmatizer.lemmatize(t) for t in new_tokens]\n",
        "    return new_tokens"
      ],
      "metadata": {
        "id": "2fIaVHwaNO6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect all sentences in the preprocessed training set\n",
        "train_sentence1 = \" \".join(train['sentence1'])\n",
        "token_s1 = tokenize(train_sentence1)\n",
        "\n",
        "train_sentence2 = \" \".join(train['sentence2'])\n",
        "token_s2 = tokenize(train_sentence2)"
      ],
      "metadata": {
        "id": "jRuDwrHWNPXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of frequent words in the train dataset\n",
        "# Count the words\n",
        "count_s1 = Counter(token_s1)\n",
        "word_freq_s1 = pd.DataFrame(count_s1.items(), columns=['Word','Frequency']).sort_values(by='Frequency', ascending=False)\n",
        "\n",
        "count_s2 = Counter(token_s2)\n",
        "word_freq_s2 = pd.DataFrame(count_s2.items(), columns=['Word','Frequency']).sort_values(by='Frequency', ascending=False)\n",
        "\n",
        "# Create subplots\n",
        "nb_ranking = 15\n",
        "fig = plt.figure(figsize=(15, 3))\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "\n",
        "sns.barplot(x='Frequency', y='Word', data=word_freq_s1.head(nb_ranking), ax=ax1).set(xlim=(0, 15000))\n",
        "ax1.set_title('Top ' + str(nb_ranking) + ' frequent words in Sentence 1: n = ' + str(len(word_freq_s1)))\n",
        "\n",
        "sns.barplot(x='Frequency', y='Word', data=word_freq_s2.head(nb_ranking), ax=ax2).set(xlim=(0, 15000))\n",
        "ax2.set_title('Top ' + str(nb_ranking) + ' frequent words in Sentence 2: n = ' + str(len(word_freq_s2)))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zO2jEQOkNSy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT"
      ],
      "metadata": {
        "id": "8zonPnO5NVZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "SLCyBHBaRGPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization using BERT Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "# Get maximum number of words\n",
        "max_len = []\n",
        "train_s1 = train['sentence1'].values\n",
        "train_s2 = train['sentence2'].values\n",
        "eval_s1 = eval['sentence1'].values\n",
        "eval_s2 = eval['sentence2'].values\n",
        "test_s1 = test['sentence1'].values\n",
        "test_s2 = test['sentence2'].values\n",
        "\n",
        "for sent1, sent2, sent3, sent4, sent5, sent6 in zip(train_s1, train_s2, eval_s1, eval_s2, test_s1, test_s2):\n",
        "    token_words_1 = tokenizer.tokenize(sent1)\n",
        "    token_words_2 = tokenizer.tokenize(sent2)\n",
        "    token_words_3 = tokenizer.tokenize(sent3)\n",
        "    token_words_4 = tokenizer.tokenize(sent4)\n",
        "    token_words_5 = tokenizer.tokenize(sent5)\n",
        "    token_words_6 = tokenizer.tokenize(sent6)\n",
        "\n",
        "    token_words_1.extend(token_words_2)\n",
        "    token_words_1.extend(token_words_3)\n",
        "    token_words_1.extend(token_words_4)\n",
        "    token_words_1.extend(token_words_5)\n",
        "    token_words_1.extend(token_words_6)\n",
        "\n",
        "    max_len.append(len(token_words_1))\n",
        "    \n",
        "max_length = max(max_len) + 3 # max length = Word tokens + 3 special tokens(1 [CLS] and 2 [SEP])\n",
        "\n",
        "print('Max words: ', max_length)"
      ],
      "metadata": {
        "id": "p6XW-GUmNUd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word embedding"
      ],
      "metadata": {
        "id": "nSAGnaH-RLUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get word ID and attention mask\n",
        "def prep(sent1, sent2, label):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  sentence_ids = []\n",
        "  end_term = \"[SEP]\"\n",
        "  labels = label.values\n",
        "\n",
        "  for x , y in zip(sent1, sent2):\n",
        "    sent= x + end_term + y\n",
        "    \n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        sent,\n",
        "        add_special_tokens = True, # Distinguish two sentences\n",
        "        max_length = max_length, # Padding\n",
        "        pad_to_max_length = True, # Padding\n",
        "        return_attention_mask = True, # Make attention mask\n",
        "        return_tensors = 'pt', # Return Pytorch tensors\n",
        "        )\n",
        "    \n",
        "    # Get word ID\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # Get attention mask\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Get token type ID (distinguish sentence 1 and 2)\n",
        "    sentence_ids.append(encoded_dict['token_type_ids'])\n",
        "    \n",
        "  # Concatenate listed tensor for vertical dimmention (dim=0)\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    \n",
        "  # Cast label list to tenosor\n",
        "  labels = torch.tensor(labels)\n",
        "\n",
        "  return input_ids, attention_masks, sentence_ids, labels"
      ],
      "metadata": {
        "id": "MBRZE3wnRNLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get word ID and attention mask\n",
        "# train\n",
        "train_ids, train_masks, sentence_ids, train_labels = prep(train_s1, train_s2, train['gold_label'])\n",
        "\n",
        "# evaluation\n",
        "eval_ids, eval_masks, sentence_ids, eval_labels = prep(eval_s1, eval_s2, eval['gold_label'])\n",
        "\n",
        "# test\n",
        "test_ids, test_masks, sentence_ids, test_labels = prep(test_s1, test_s2, test['gold_label'])"
      ],
      "metadata": {
        "id": "8ePYtVBCRTTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample tensor\n",
        "print('Original sentence1: ', train_s1[0])\n",
        "print('Original sentence2: ', train_s2[0])\n",
        "print('Token IDs:', train_ids[0]) \n",
        "print('Attention mask:', train_masks[0])"
      ],
      "metadata": {
        "id": "9fzBkD4LRU6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and evaluation"
      ],
      "metadata": {
        "id": "Zui9TpZZRWYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make tensor dataset\n",
        "train_tensor = TensorDataset(train_ids, train_masks, train_labels)\n",
        "eval_tensor = TensorDataset(eval_ids, eval_masks, eval_labels)\n",
        "test_tensor = TensorDataset(test_ids, test_masks, test_labels)\n",
        "\n",
        "# Data loader\n",
        "batch_size = 50\n",
        "\n",
        "# Train data loader\n",
        "train_dataloader = DataLoader(\n",
        "            train_tensor,  \n",
        "            sampler = RandomSampler(train_tensor), # make batches randomly\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "# Evaluation data loader\n",
        "validation_dataloader = DataLoader(\n",
        "            eval_tensor, \n",
        "            sampler = SequentialSampler(eval_tensor), # make batches in order\n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "# Test data loader\n",
        "test_dataloader = DataLoader(\n",
        "            test_tensor, \n",
        "            sampler = SequentialSampler(test_tensor), # make batches in order\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Enable GPU if possible\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load a pre-traind BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Specify a pre-trained model\n",
        "    num_labels = 3,\n",
        "    output_attentions = False, # Output attention vectors\n",
        "    output_hidden_states = False, # Output hidden layers\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "ln6xJI-1RjMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make tensor dataset\n",
        "train_tensor = TensorDataset(train_ids, train_masks, train_labels)\n",
        "eval_tensor = TensorDataset(eval_ids, eval_masks, eval_labels)\n",
        "test_tensor = TensorDataset(test_ids, test_masks, test_labels)\n",
        "\n",
        "# Data loader\n",
        "batch_size = 50\n",
        "\n",
        "# Train data loader\n",
        "train_dataloader = DataLoader(\n",
        "            train_tensor,  \n",
        "            sampler = RandomSampler(train_tensor), # make batches randomly\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "# Evaluation data loader\n",
        "validation_dataloader = DataLoader(\n",
        "            eval_tensor, \n",
        "            sampler = SequentialSampler(eval_tensor), # make batches in order\n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "# Test data loader\n",
        "test_dataloader = DataLoader(\n",
        "            test_tensor, \n",
        "            sampler = SequentialSampler(test_tensor), # make batches in order\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "metadata": {
        "id": "zpS0OoMPRofM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable GPU if possible\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load a pre-traind BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Specify a pre-trained model\n",
        "    num_labels = 3,\n",
        "    output_attentions = False, # Output attention vectors\n",
        "    output_hidden_states = False, # Output hidden layers\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "HUJ4g9HUR50U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "\n",
        "# Train and evaluation\n",
        "lr = 2e-5 # Learning rate\n",
        "optimizer = AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "max_epoch = 50\n",
        "train_loss_ = []\n",
        "eval_loss_ = []\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, max_epoch))\n",
        "    # Training sequence\n",
        "    print('Training...')\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # Loss means Cross Entropy Loss\n",
        "        # Logits means values to be input to the softmax function\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids = None, \n",
        "                             attention_mask = b_input_mask, \n",
        "                             labels = b_labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_dataloader)  \n",
        "    train_loss_.append(round(avg_train_loss, 2))\n",
        "    print('Epoch training loss: ', round(avg_train_loss, 2))\n",
        "    print('')\n",
        "\n",
        "    # Evaluation sequence\n",
        "    print('Evaluating...')\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    for batch in validation_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        with torch.no_grad(): # don't compute grading\n",
        "          (loss, logits) = model(b_input_ids, \n",
        "                                 token_type_ids = None, \n",
        "                                 attention_mask = b_input_mask,\n",
        "                                 labels = b_labels)\n",
        "        val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(validation_dataloader)\n",
        "    eval_loss_.append(round(avg_val_loss, 2))\n",
        "    print('Epoch evaluation loss: ', round(avg_val_loss, 2))\n",
        "    print('')\n"
      ],
      "metadata": {
        "id": "TLQBIoq6SX2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss\n",
        "plt.plot(list(range(1, max_epoch+1)), train_loss_, color='red', marker='o')\n",
        "plt.plot(list(range(1, max_epoch+1)), eval_loss_, color='green', marker='^')\n",
        "plt.gca().get_xaxis().set_major_locator(ticker.MaxNLocator(integer=True))\n",
        "plt.title('Model loss\\nEpoch = ' + str(max_epoch))\n",
        "plt.legend(['Train loss', 'Evaluation loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Average cross entropy loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9z_h31bOSi7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction and model performance checking"
      ],
      "metadata": {
        "id": "yIUnsBt0SoyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "prediction = []\n",
        "true_labels = []\n",
        "\n",
        "# Switch the data loader (use validation or test dataloader)\n",
        "dataloader_mode = validation_dataloader\n",
        "#dataloader_mode = test_dataloader\n",
        "\n",
        "model.eval() # Turn off training mode\n",
        "for batch in dataloader_mode:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():   \n",
        "        # Get prediction by trained model\n",
        "        preds = model(b_input_ids,\n",
        "                      token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "        prediction.append(preds[0].detach().cpu().numpy())\n",
        "        true_labels.append(b_labels.detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "kNKV9Yr3SsiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract relevant information from prediction\n",
        "# Logits list\n",
        "results = []\n",
        "for i in range(len(prediction)):\n",
        "  for j in range(len(prediction[0])):\n",
        "    results.append(prediction[i][j])\n",
        "\n",
        "logits_df = pd.DataFrame(results, columns=['logit_0', 'logit_1', 'logit_2'])\n",
        "\n",
        "# Predicted label list\n",
        "predicted_label = []\n",
        "for i in results:\n",
        "  predicted_label.append(np.argmax(i, axis=0))\n",
        "\n",
        "pred_df = pd.DataFrame(predicted_label, columns=['pred_label'])\n",
        "\n",
        "# True label list\n",
        "true_labels2 = []\n",
        "for i in range(len(true_labels)):\n",
        "  for j in range(batch_size):\n",
        "    true_labels2.append(true_labels[i][j])\n",
        "\n",
        "label_df = pd.DataFrame(true_labels2, columns=['true_label'])"
      ],
      "metadata": {
        "id": "8lCRLNCIStSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a dataframe to calculate the performance of prediction\n",
        "preds_df = pd.concat([logits_df, pred_df, label_df], axis=1)\n",
        "preds_df.head()"
      ],
      "metadata": {
        "id": "8G8z0nIaSvgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance score\n",
        "\n",
        "y_pred = preds_df.pred_label.values\n",
        "y_true = preds_df.true_label.values\n",
        "\n",
        "print(classification_report(y_true, y_pred, digits=2))"
      ],
      "metadata": {
        "id": "C6S4x-hkSy5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize confusion matrix\n",
        "\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "matrix = sns.heatmap(cf_matrix, annot=True)\n",
        "matrix.xaxis.set_ticks_position('top') \n",
        "matrix.set(xlabel='prediction', ylabel='Gold label')\n",
        "plt.title('Confusion Matrix\\n0=Neutral, 1=Entailment, 2=Contradiction')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y3KLC-_GS26h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}