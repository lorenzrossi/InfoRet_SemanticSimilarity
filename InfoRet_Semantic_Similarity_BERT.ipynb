{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzrossi/InfoRet_SemanticSimilarity/blob/main/InfoRet_Semantic_Similarity_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICord5RYWE9U",
        "outputId": "66671a90-74d8-403c-904c-4ca914e12b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from opendatasets) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2.25.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2022.12.7)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (7.0.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle->opendatasets) (4.0.0)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers~=2.11.0\n",
            "  Downloading transformers-2.11.0-py3-none-any.whl (674 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m674.8/674.8 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from transformers~=2.11.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers~=2.11.0) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers~=2.11.0) (3.9.0)\n",
            "Collecting tokenizers==0.7.0\n",
            "  Downloading tokenizers-0.7.0-cp38-cp38-manylinux1_x86_64.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers~=2.11.0) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers~=2.11.0) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers~=2.11.0) (4.64.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers~=2.11.0) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers~=2.11.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers~=2.11.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers~=2.11.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers~=2.11.0) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers~=2.11.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers~=2.11.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers~=2.11.0) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=bcb6999fbb42afcc2771ca2ce504ccb39cae2fda0c0c6daf3e52763249ec7b5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.7.0 transformers-2.11.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreTrueAction(option_strings=['--no_train'], dest='no_train', nargs=0, const=True, default=False, type=None, choices=None, help=\"Don't train model, load model and quit\", metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, classification_report, hamming_loss\n",
        "import shutil \n",
        "import sys\n",
        "import time, datetime, json\n",
        "\n",
        "!pip install opendatasets\n",
        "import opendatasets as op\n",
        "\n",
        "import os\n",
        "\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "# NLTK\n",
        "import nltk as nlp\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import ngrams\n",
        "nlp.download('stopwords')\n",
        "nlp.download('popular')\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# PYTORCH\n",
        "!pip install transformers~=2.11.0\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, AdamWeightDecay, get_linear_schedule_with_warmup\n",
        "import random\n",
        "import gc\n",
        "\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--data_dir', default='data',\n",
        "                    help=\"Directory to download dataset\")\n",
        "parser.add_argument('--preprocessed_dir', default='preprocessed_data',\n",
        "                    help=\"Directory to save preprocessed datasets\")\n",
        "parser.add_argument('--model_dir', default=\"saved-model\",\n",
        "                    help=\"Directory to save model after training\")\n",
        "\n",
        "parser.add_argument('--config', default=\"config.ini\",\n",
        "                    help=\"INI file for model configuration\")\n",
        "\n",
        "parser.add_argument('--epochs', help=\"Number of epochs to train for\")\n",
        "parser.add_argument('--batch_size', help=\"Batch Size for Training/Validation/Testing on dataset\")\n",
        "\n",
        "parser.add_argument('--download_dataset', action='store_true',\n",
        "                    help=\"If set, download the dataset to a specified location\")\n",
        "parser.add_argument('--bert_size', default=\"base\", choices=[\"base\", \"large\"],\n",
        "                    help=\"Size of pretrained BERT to use (base or large)\")\n",
        "parser.add_argument('--cased', default=False,\n",
        "                    help=\"Use argument when you think casing is important\")\n",
        "parser.add_argument('--num_labels',\n",
        "                    help=\"Number of labels to classify for given dataset\")\n",
        "\n",
        "parser.add_argument('--output_attentions', action='store_true',\n",
        "                    help=\"Output attention values from BERT Model\")\n",
        "parser.add_argument('--output_hidden_states', action='store_true',\n",
        "                    help=\"Output embeddings generated from BERT layers\")\n",
        "parser.add_argument('--gpu', action='store_true',\n",
        "                    help=\"Use GPU for training if available\")\n",
        "parser.add_argument('--predict_on_test', action='store_true',\n",
        "                    help=\"Load model from file and run on test set\")\n",
        "parser.add_argument('--no_train', action='store_true',\n",
        "                    help=\"Don't train model, load model and quit\")"
      ],
      "metadata": {
        "id": "AUl9VR1p-esd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q12KZ2lWFrG",
        "outputId": "3ba00d63-3b94-4b27-92c9-92b8cf36b28a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-24 13:30:02--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-01-24 13:30:03--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.11MB/s    in 3m 19s  \n",
            "\n",
            "2023-01-24 13:33:23 (4.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n",
        "# bcc30972b8b9f25c2bc6c0a46d8f4d62"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ggx6Z93sUmMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82a6c12-5161-4c93-f240-b6c4c51c9f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: lorenzrossi\n",
            "Your Kaggle Key: ··········\n",
            "Downloading stanford-natural-language-inference-corpus.zip to ./stanford-natural-language-inference-corpus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.4M/44.4M [00:02<00:00, 15.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "op.download(\"https://www.kaggle.com/datasets/stanfordu/stanford-natural-language-inference-corpus\")\n",
        "url = \"https://www.kaggle.com/datasets/stanfordu/stanford-natural-language-inference-corpus\"\n",
        "dataset_folder ='stanford-natural-language-inference-corpus'\n",
        "preprocessed_folder = 'snli-preprocessed'\n",
        "saved_model_location = 'saved_models'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SPECIAL_TOKENS = {\n",
        "    'CLS': ['[CLS]'],\n",
        "    'SEP': ['[SEP]']\n",
        "}\n",
        "\n",
        "SNLI_DATASET_URL = {\n",
        "    \"train_folder\": \"stanford-natural-language-inference-corpus/snli_1.0_train.csv\",\n",
        "    \"validation_folder\": \"stanford-natural-language-inference-corpus/snli_1.0_dev.csv\",\n",
        "    \"test_folder\": \"stanford-natural-language-inference-corpus/snli_1.0_test.csv\"\n",
        "}\n",
        "\n",
        "SNLI_FILE_NAMES = {\n",
        "    \"train\": \"snli_1.0_train.csv\",\n",
        "    \"validation\": \"snli_1.0_dev.csv\",\n",
        "    \"test\": \"snli_1.0_test.csv\"\n",
        "}"
      ],
      "metadata": {
        "id": "8vkkeS_WofOp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf-Jmdc7MjBR"
      },
      "source": [
        "# PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters for preprocessing, tokenization and word embedding\n",
        "\n",
        "max_len_tokens = 256\n",
        "\n",
        "dataset_labels = {\"contradiction\": 0,\n",
        "\"entailment\": 1,\n",
        "\"neutral\": 2}\n",
        "\n",
        "DATASET_LABELS = {}\n",
        "for k, v in dataset_labels.items():\n",
        "    DATASET_LABELS[k] = int(v)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8c15ebea8874443a8cc7e2776943a9ef",
            "2423a23fb25a40c685e987074eec4e78",
            "4600f4c1eedd49dfbdfde45af65c2b23",
            "d47107159a324b1eaaf40335d0773016",
            "f0ed889a732f46beb49a673fd15ace8d",
            "aa81b75cc94543f8915f8c4e4ab54b09",
            "dce39f132650478eab0f9db9b700744f",
            "9b62015e435347d3b95215d56e36905b",
            "d3484678a37e4013b404a2d96efe7930",
            "b136993e8fee45fda09f781333c49055",
            "7f839f9c1f2d4e88a16192d288b5cfdf"
          ]
        },
        "id": "lEbfO38XErXa",
        "outputId": "1735ce38-9715-4934-8841-430a44158e84"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c15ebea8874443a8cc7e2776943a9ef"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_LABELS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ptd8LdNErXX",
        "outputId": "7bcb8706-3d3e-408c-9122-a261693debd0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'contradiction': 0, 'entailment': 1, 'neutral': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SNLIDataset(object):\n",
        "    \"\"\"\n",
        "    Class to handle datasets and\n",
        "    preprocess them in order to pass them on\n",
        "    to the model for training/testing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, tokenizer, dataset_folder, preprocessed_folder, batch_size,\n",
        "        max_len_tokens, dataset_labels, download_dataset=False, use_padding=True\n",
        "    ):\n",
        "\n",
        "        self.dataset_folder = dataset_folder\n",
        "        self.preprocessed_folder = preprocessed_folder\n",
        "        self.batch_size = batch_size\n",
        "        self.use_padding = use_padding\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len_tokens = max_len_tokens\n",
        "\n",
        "        self.dataset_labels = dataset_labels\n",
        "\n",
        "        if download_dataset:\n",
        "            self.download_dataset()\n",
        "\n",
        "        train_data = os.path.join(self.dataset_folder, SNLI_FILE_NAMES[\"train\"])\n",
        "        validation_data = os.path.join(self.dataset_folder, SNLI_FILE_NAMES[\"validation\"])\n",
        "        test_data = os.path.join(self.dataset_folder, SNLI_FILE_NAMES[\"test\"])\n",
        "\n",
        "        self.train_raw = pd.read_csv(train_data, index_col=1)\n",
        "        self.train_raw = self.train_raw.sample(frac=0.2)\n",
        "        \n",
        "        self.eval_raw = pd.read_csv(validation_data, index_col=1)\n",
        "        #self.eval_raw = self.eval_raw.sample(frac=0.5)\n",
        "\n",
        "        self.test_raw = pd.read_csv(test_data, index_col=1)\n",
        "        #self.test_raw = self.test_raw.sample(frac=0.5)\n",
        "\n",
        "    def download_dataset(self):\n",
        "\n",
        "       print(\"Downloading SNLI Dataset in CSV format\")\n",
        "       \n",
        "       if not os.path.exists(self.dataset_folder):\n",
        "           os.mkdir(self.dataset_folder)\n",
        "       \n",
        "       download_location = self.dataset_folder\n",
        "       \n",
        "       train_data_url = SNLI_DATASET_URL[\"train\"]\n",
        "       validation_data_url = SNLI_DATASET_URL[\"validation\"]\n",
        "       test_data_url = SNLI_DATASET_URL[\"test\"]\n",
        "       \n",
        "       if os.path.exists(os.path.join(download_location)):\n",
        "           print(\"Test Data already present\")\n",
        "       \n",
        "       else:\n",
        "           dataset = op.download(url, out=download_location)\n",
        "       \n",
        "       print(f\"Dataset downloaded successfully in {download_location}\")\n",
        "       \n",
        "       return\n",
        "\n",
        "    def preprocess_dataset_util(self, dataset_df):\n",
        "    \n",
        "        tokenizer = self.tokenizer\n",
        "        labels_dict = self.dataset_labels\n",
        "        \n",
        "        def tokenize_sentence(tokenizer, input_sentence):\n",
        "        \n",
        "            return tokenizer.tokenize(input_sentence)\n",
        "            \n",
        "        sentence_A = dataset_df.sentence1.to_numpy()\n",
        "        sentence_B = dataset_df.sentence2.to_numpy()\n",
        "        labels = dataset_df.gold_label.to_numpy()            \n",
        "                 \n",
        "        sentence_A_tokens = []\n",
        "        sentence_B_tokens = []\n",
        "        processed_labels = []\n",
        "\n",
        "        for i, j, k in zip(sentence_A, sentence_B, labels):\n",
        "            try:\n",
        "                if k == '-':\n",
        "                    continue\n",
        "                \n",
        "                t1 = tokenize_sentence(tokenizer, i)\n",
        "                t2 = tokenize_sentence(tokenizer, j)\n",
        "                \n",
        "                sentence_A_tokens.append(t1)\n",
        "                sentence_B_tokens.append(t2)\n",
        "                \n",
        "                label = labels_dict[k]\n",
        "                processed_labels.append(label)\n",
        "            \n",
        "            except Exception as e:\n",
        "                \n",
        "                print(e)\n",
        "                print(\"Skipping over sentence pair!\")\n",
        "                \n",
        "                continue\n",
        "        \n",
        "        sentence_tokens = []\n",
        "        input_ids = []\n",
        "        token_lengths = []\n",
        "        \n",
        "        CLS_TOKEN = SPECIAL_TOKENS['CLS']\n",
        "        SEP_TOKEN = SPECIAL_TOKENS['SEP']\n",
        "        \n",
        "        for i, j in zip(sentence_A_tokens, sentence_B_tokens):\n",
        "        \n",
        "            sentence = CLS_TOKEN + i + SEP_TOKEN + j + SEP_TOKEN\n",
        "            \n",
        "            token_ids = tokenizer.convert_tokens_to_ids(sentence)     \n",
        "            sentence_tokens.append(sentence)\n",
        "            \n",
        "            token_lengths.append(len(token_ids))      \n",
        "            input_ids.append(token_ids)\n",
        "        \n",
        "        return np.array(sentence_tokens), np.array(input_ids), np.array(token_lengths), np.array(processed_labels)\n",
        "    \n",
        "    def preprocess_dataset(self, d_partition=\"train_raw\"):\n",
        "    \n",
        "        print(f\"Preprocessing {d_partition} data\")\n",
        "        \n",
        "        if d_partition.lower() not in [\"train\", \"validation\", \"test\"]:\n",
        "            \n",
        "            raise BaseException(\n",
        "                \"d_partition must be train, validation or test\")\n",
        "        \n",
        "        if not os.path.exists(self.preprocessed_folder):\n",
        "            os.mkdir(self.preprocessed_folder)\n",
        "        \n",
        "        preprocessed_location = self.preprocessed_folder\n",
        "        file_name_base = os.path.join(preprocessed_folder, d_partition + \"_\")\n",
        "\n",
        "        \n",
        "        if os.path.exists(file_name_base + \"tokens.npy\"):           \n",
        "            print(\"Retrieving tokens from .npy files\")\n",
        "            \n",
        "            tokens = np.load(file_name_base + \"tokens.npy\", allow_pickle=True)\n",
        "            ids = np.load(file_name_base + \"token-ids.npy\", allow_pickle=True)\n",
        "            \n",
        "            lengths = np.load(file_name_base + \"token-lengths.npy\", allow_pickle=True)\n",
        "            labels = np.load(file_name_base + \"labels.npy\", allow_pickle=True)\n",
        "        \n",
        "        else:\n",
        "            if d_partition.lower() == \"train\":\n",
        "                dataset_df = self.train_raw\n",
        "            \n",
        "            elif d_partition.lower() == \"validation\":\n",
        "                dataset_df = self.eval_raw\n",
        "            \n",
        "            else:\n",
        "                dataset_df = self.test_raw\n",
        "            \n",
        "            tokens, ids, lengths, labels = self.preprocess_dataset_util(dataset_df)\n",
        "            \n",
        "            np.save(file_name_base + \"tokens.npy\", tokens)\n",
        "            np.save(file_name_base + \"token-ids.npy\", ids)\n",
        "            np.save(file_name_base + \"token-lengths.npy\", lengths)\n",
        "            np.save(file_name_base + \"labels.npy\", labels)\n",
        "        \n",
        "        print(f\"Saving preprocessed {d_partition} data\")\n",
        "        \n",
        "        return (tokens, ids, lengths, labels)\n",
        "    \n",
        "    def pad_and_create_attention_masks(self, input_ids):      \n",
        "        max_len_tokens = self.max_len_tokens       \n",
        "        if self.use_padding:\n",
        "            input_ids = pad_sequences(input_ids, maxlen=max_len_tokens, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "        \n",
        "        attention_masks = []       \n",
        "        for sentence in input_ids:\n",
        "            attention_mask = [int(token_id > 0) for token_id in sentence]\n",
        "            attention_masks.append(attention_mask)\n",
        "        \n",
        "        return input_ids, attention_masks\n",
        "    \n",
        "    def convert_data_to_tensor_dataset(self, tokens, attention_masks, labels):\n",
        "        \n",
        "        batch_size = self.batch_size \n",
        "\n",
        "        tokens = torch.tensor(tokens)       \n",
        "        attention_masks = torch.tensor(attention_masks)       \n",
        "        labels = torch.tensor(labels)   \n",
        "\n",
        "        data = TensorDataset(tokens, attention_masks, labels)\n",
        "        sampler = RandomSampler(data)        \n",
        "        dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
        "        \n",
        "        return (data, sampler, dataloader)\n",
        "    \n",
        "    def labels(self):\n",
        "        return self.dataset_labels"
      ],
      "metadata": {
        "id": "wWpnEII1_ZRY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = SNLIDataset(tokenizer = tokenizer, \n",
        "                      dataset_folder = dataset_folder, \n",
        "                      preprocessed_folder = preprocessed_folder, \n",
        "                      batch_size = 32, \n",
        "                      max_len_tokens = 256, \n",
        "                      dataset_labels = DATASET_LABELS, \n",
        "                      download_dataset=False, \n",
        "                      use_padding=True)"
      ],
      "metadata": {
        "id": "3lp2a_Jy2M-4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLCyBHBaRGPN"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens, train_input_ids, train_token_lenghts, train_labels = dataset.preprocess_dataset(d_partition=\"train\")\n",
        "validation_tokens, validation_input_ids, validation_token_lenghts, validation_labels = dataset.preprocess_dataset(d_partition=\"validation\")\n",
        "test_tokens, test_input_ids, test_token_lenghts, test_labels = dataset.preprocess_dataset(d_partition=\"test\")\n",
        "print(\"Padding inputs and creating attention masks\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9E50AJ64LpP",
        "outputId": "4f56b34f-6cdc-43db-eb68-1c215f3e9488"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing train data\n",
            "'float' object has no attribute 'strip'\n",
            "Skipping over sentence pair!\n",
            "'float' object has no attribute 'strip'\n",
            "Skipping over sentence pair!\n",
            "'float' object has no attribute 'strip'\n",
            "Skipping over sentence pair!\n",
            "'float' object has no attribute 'strip'\n",
            "Skipping over sentence pair!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-e048c1186222>:116: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(sentence_tokens), np.array(input_ids), np.array(token_lengths), np.array(processed_labels)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving preprocessed train data\n",
            "Preprocessing validation data\n",
            "Saving preprocessed validation data\n",
            "Preprocessing test data\n",
            "Saving preprocessed test data\n",
            "Padding inputs and creating attention masks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSAGnaH-RLUb"
      },
      "source": [
        "# Word embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids, train_attention_masks = dataset.pad_and_create_attention_masks(train_input_ids)\n",
        "\n",
        "validation_input_ids, validation_attention_masks = dataset.pad_and_create_attention_masks(validation_input_ids)\n",
        "\n",
        "test_input_ids, test_attention_masks = dataset.pad_and_create_attention_masks(test_input_ids)\n",
        "\n",
        "print(\"Converting dataset to PyTorch TensorDataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwi5_g-1Ea84",
        "outputId": "65bf1986-fca4-43e0-a068-aa2106454d8d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting dataset to PyTorch TensorDataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_sampler, train_dataloader = dataset.convert_data_to_tensor_dataset(train_input_ids, train_attention_masks, train_labels)\n",
        "\n",
        "validation_data, validation_sampler, validation_dataloader = dataset.convert_data_to_tensor_dataset(validation_input_ids, validation_attention_masks, validation_labels)\n",
        "\n",
        "test_data, test_sampler, test_dataloader = dataset.convert_data_to_tensor_dataset(test_input_ids, test_attention_masks, test_labels)"
      ],
      "metadata": {
        "id": "6raGu5QCEfW-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zonPnO5NVZE"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1esLFFwDSjms"
      },
      "outputs": [],
      "source": [
        "class BERTModel:\n",
        "\n",
        "    def __init__(self, train_dataloader, num_labels, model_size, cased,\n",
        "                 output_attentions, output_hidden_states,\n",
        "                 optimizer, lr, eps, beta1, beta2,\n",
        "                 weight_decay, correct_bias, epochs):\n",
        "        \"\"\"\n",
        "            Args:\n",
        "            train_dataloder: (torch.utils.data.TensorDataset) Dataloder for the Training Set\n",
        "            num_labels: (int) Number of output labels\n",
        "            model_size: (str) Size of BERT Model [\"base\", \"large\"]\n",
        "            cased: (bool) Use cased or uncased BERT model\n",
        "            output_attentions: (bool) Output attention values from BERT Model\n",
        "            output_hidden_states: (bool) Output embeddings generated from BERT layers\n",
        "            optimizer: (str) Name of the Optimizer [\"AdamW\", \"AdamWeightDecay\"]\n",
        "            lr: (float) Learning Rate for the optimizer\n",
        "            eps: (float) Epsilon value for optimizer\n",
        "            beta1: (float) Beta1 value for Adam optimizer\n",
        "            beta2: (float) Beta2 value for Adam optimizer\n",
        "            weight_decay: (float) Weight Decay value for Adam optimizer\n",
        "            correct_bias: (float) Correct for bias terms in Adam Optimizer, default = True\n",
        "            epochs: (int) Number of epochs to run the model.\n",
        "        \"\"\"\n",
        "\n",
        "        self.num_labels = num_labels\n",
        "        self.model_size = model_size\n",
        "        self.cased = cased\n",
        "        self.output_attentions = output_attentions\n",
        "        self.output_hidden_states = output_hidden_states\n",
        "\n",
        "        self.lr = lr\n",
        "        self.eps = eps\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.weight_decay = weight_decay\n",
        "        self.correct_bias = correct_bias\n",
        "\n",
        "        self._train_dataloader = train_dataloader\n",
        "        self._epochs = epochs\n",
        "\n",
        "        cased_ = \"uncased\" if not cased else \"cased\"\n",
        "        model_name = f\"bert-{model_size}-{cased_}\"\n",
        "\n",
        "        model = BertForSequenceClassification.from_pretrained(\n",
        "                    model_name,\n",
        "                    num_labels=num_labels,\n",
        "                    output_attentions=output_attentions,\n",
        "                    output_hidden_states=output_hidden_states\n",
        "        )\n",
        "\n",
        "        if optimizer == \"AdamWeightDecay\":\n",
        "            optimizer = AdamWeightDecay(model.parameters(), learning_rate=lr, \n",
        "                                        beta_1=beta1, beta_2=beta2, epsilon=eps, weight_decay_rate=weight_decay)\n",
        "        else:\n",
        "            optimizer = AdamW(model.parameters(), lr=lr, eps=eps, \n",
        "                              betas=(beta1, beta2), weight_decay=weight_decay, correct_bias=correct_bias)\n",
        "\n",
        "        total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                    num_warmup_steps=0,\n",
        "                                                    num_training_steps=total_steps)\n",
        "\n",
        "        self._optimizer = optimizer\n",
        "        self._model = model\n",
        "        self._scheduler = scheduler\n",
        "\n",
        "    def model(self):\n",
        "        return self._model\n",
        "\n",
        "    def optimizer(self):\n",
        "        return self._optimizer\n",
        "\n",
        "    def scheduler(self):\n",
        "        return self._scheduler\n",
        "\n",
        "    def epochs(self):\n",
        "        return self._epochs\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self._train_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 4\n",
        "BATCH_SIZE = 32\n",
        "MODEL_PARAMS = {\n",
        "    'learning_rate': 2e-05,\n",
        "    'epsilon': 1e-08,\n",
        "    'beta1': 0.9,\n",
        "    'beta2': 0.999,\n",
        "    'weight_decay': 0.0,\n",
        "    'correct_bias': True\n",
        "}\n",
        "\n",
        "grad_clip_value = 1.0\n",
        "batch_print_freq = 200\n",
        "seed_value = 42\n",
        "\n",
        "DOWNLOAD_DATASET = False\n",
        "if SNLIDataset.download_dataset:\n",
        "    DOWNLOAD_DATASET = True\n",
        "\n",
        "MODEL_SIZE = \"base\"\n",
        "CASED = \"uncased\"\n",
        "\n",
        "num_labels = len(DATASET_LABELS)\n",
        "\n",
        "#USE_GPU = True\n",
        "#\n",
        "#RUN_PREDICTIONS = True\n",
        "#NO_TRAIN = True\n",
        "\n",
        "model_name = f\"bert-{MODEL_SIZE}-{CASED}\"\n",
        "\n",
        "BERTModel = BERTModel(\n",
        "      train_dataloader=train_dataloader,\n",
        "      num_labels = num_labels,\n",
        "      model_size = MODEL_SIZE,\n",
        "      cased = CASED,\n",
        "      output_attentions = True,\n",
        "      output_hidden_states = True,\n",
        "      optimizer = \"AdamW\",\n",
        "      lr = MODEL_PARAMS[\"learning_rate\"],\n",
        "      eps = MODEL_PARAMS[\"epsilon\"],\n",
        "      beta1 = MODEL_PARAMS[\"beta1\"],\n",
        "      beta2 = MODEL_PARAMS[\"beta2\"],\n",
        "      weight_decay = MODEL_PARAMS[\"weight_decay\"],\n",
        "      correct_bias = MODEL_PARAMS[\"correct_bias\"],\n",
        "      epochs=EPOCHS\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "93cf2d30a6214a4aacacd4da6ee87938",
            "79a60e17a59540f4a0bde4a877915240",
            "cabbf70b8c2d417d9383fa52ab3a61ef",
            "dd34b72844a0457ab29e64bad10bf6d7",
            "629f7ab1ec0e43ec8f7f4c624d7a1807",
            "e53dd3a8b88342f7baa169a8130a49e8",
            "a69ba5fc1ff24496a0faf27b80605fb2",
            "6688bae75e0e4857a29dfc8094e2f075",
            "2b74233af799403f80d381be6ca3d266",
            "bd57080e2f1b47c98669ff21793957fd",
            "ca01f29f56494b4881fd1e872d09b423",
            "96f5df13001944b8a9251d1399275d4c",
            "fc5a2df76ca64be4b79cb34c873171ad",
            "11b75ac1f4e94a20a03483ef16e30b98",
            "6a24a55765ff4d40a3c890c3e2f21aa4",
            "3746f1d41d624faca6ce486966684739",
            "e79996fec86d461faf06f6d04562a0f8",
            "2e701e025ec34eb2bae1343aa5b3abfd",
            "a7be121171094d2283f930bfd653848e",
            "aa39eca7a2714f88a1f77cf5e14ff8cb",
            "74583e2b76b34df499f55685e5be0795",
            "4c9f763efddd4d3eae7ee3f34230dbf7"
          ]
        },
        "id": "AQ_TXqfeHhIH",
        "outputId": "95188650-2035-4df7-d7eb-7e8979c8fdae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93cf2d30a6214a4aacacd4da6ee87938"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96f5df13001944b8a9251d1399275d4c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zui9TpZZRWYN"
      },
      "source": [
        "# Training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lQm_bxyEVyAt"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round(elapsed))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "7vaofW6Hhjdr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TLQBIoq6SX2M"
      },
      "outputs": [],
      "source": [
        "# Train and evaluation\n",
        "def train_and_evaluate_bert(BERTModel, validation_dataloader, use_gpu, seed_value, batch_print_freq, grad_clip_value):\n",
        "    \"\"\"\n",
        "    Train the BERT Model\n",
        "    Args:\n",
        "        BERTModel: (models.bert) Object of BERTModel class, containing model, optimizer and scheduler\n",
        "        validation_dataloder: (torch.utils.data.TensorDataset) Dataloder for the Validation Set\n",
        "        use_gpu: (bool) Use GPU if available for training\n",
        "        seed_value: (int) Seed Value for random number generation\n",
        "        batch_print_freq: (int) Number of batches after which info is logged\n",
        "        grad_clip_value: (float) Max value of gradient, higher gradients are clipped to this value\n",
        "    \"\"\"\n",
        "\n",
        "    if use_gpu and torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"There are {torch.cuda.device_count()} GPU(s) available\")\n",
        "        print(f\"Using {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"Using CPU\")\n",
        "\n",
        "    model = BERTModel.model()\n",
        "    optimizer = BERTModel.optimizer()\n",
        "    scheduler = BERTModel.scheduler()\n",
        "    epochs = BERTModel.epochs()\n",
        "    train_dataloader = BERTModel.train_dataloader()\n",
        "\n",
        "    print(\"Model, Optimizer and Scheduler setup successfully!\")\n",
        "\n",
        "    if use_gpu:\n",
        "        model.cuda()\n",
        "\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    if use_gpu:\n",
        "        torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "    loss_values = []\n",
        "    metrics = []\n",
        "\n",
        "    print(\"Training started\")\n",
        "\n",
        "    t = range(epochs)\n",
        "    for epoch in t:\n",
        "        epMetric = {}\n",
        "        print(f\"Epoch {epoch + 1} / {epochs}\")\n",
        "        epMetric[\"epoch\"] = epoch + 1\n",
        "        start_time = time.time()\n",
        "        total_loss = 0\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            if step % batch_print_freq == 0 and not step == 0:\n",
        "                elapsed = time.time() - start_time\n",
        "                time_per_batch = elapsed / step\n",
        "                time_remaining = (len(train_dataloader) -\n",
        "                                  step) * time_per_batch\n",
        "                print(f\"\\nBatch {step} of {len(train_dataloader)}. Elapsed: {format_time(elapsed)}\")\n",
        "                print(f\"Time left in this epoch: {format_time(time_remaining)}\")\n",
        "\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            output = model(b_input_ids,\n",
        "                           token_type_ids=None,\n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels)\n",
        "\n",
        "            loss = output[0]\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_value)\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        loss_values.append(avg_train_loss)\n",
        "\n",
        "        p_time = time.time()\n",
        "        time_taken_train = format_time(p_time - start_time)\n",
        "\n",
        "        epMetric[\"time_taken_train\"] = time_taken_train\n",
        "        epMetric[\"epoch_avg_loss\"] = avg_train_loss\n",
        "\n",
        "        print(f\"\\n Average Training Loss: {avg_train_loss} \")\n",
        "        print(f\"Training Epoch Time: {time_taken_train} \\n\")\n",
        "\n",
        "        print(\"Validation\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        model.eval()\n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        nb_eval_steps = 0\n",
        "\n",
        "        for batch in validation_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(b_input_ids,\n",
        "                                token_type_ids=None,\n",
        "                                attention_mask=b_input_mask)\n",
        "\n",
        "            logits = outputs[0]\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "            nb_eval_steps += 1\n",
        "\n",
        "        p_time = time.time()\n",
        "        time_taken_validation = format_time(p_time - start_time)\n",
        "        validation_accuracy = eval_accuracy / nb_eval_steps\n",
        "\n",
        "        epMetric[\"time_taken_validation\"] = time_taken_validation\n",
        "        epMetric[\"validation_accuracy\"] = validation_accuracy\n",
        "\n",
        "        print(f\"Accuracy: {validation_accuracy}\")\n",
        "        print(f\"Validation Took: {time_taken_validation}\")\n",
        "\n",
        "        metrics.append(epMetric)\n",
        "\n",
        "    print(\"Training Complete\")\n",
        "\n",
        "    return (model, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_from_file(saved_model_location):\n",
        "\n",
        "    model_weight_dir = saved_model_location\n",
        "\n",
        "    if not os.path.exists(model_weight_dir):\n",
        "        raise Exception(f\"Directory {saved_model_location} doesn't exist\")\n",
        "\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        model_weight_dir,\n",
        "        output_hidden_states=True\n",
        "    )\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_weight_dir)\n",
        "\n",
        "    print(f\"Loaded pretrained model and tokenizer from {model_weight_dir}\")\n",
        "\n",
        "    return (model, tokenizer)\n",
        "\n",
        "\n",
        "def run_model_on_test_set(test_dataloader, saved_model_location, use_gpu, batch_print_freq):\n",
        "\n",
        "    if use_gpu and torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"There are {torch.cuda.device_count()} GPU(s) available\")\n",
        "        print(f\"Using {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"Using CPU\")\n",
        "\n",
        "    model, _ = load_model_from_file(saved_model_location)\n",
        "    model.cuda()\n",
        "\n",
        "    predictions, true_labels = [], []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, batch in enumerate(test_dataloader):\n",
        "        if idx % batch_print_freq == 0 and idx != 0:\n",
        "            print(f\"Done with batch {idx} of {len(test_dataloader)}\")\n",
        "            elapsed = time.time() - start_time\n",
        "            time_per_batch = elapsed / idx\n",
        "            time_remaining = (len(test_dataloader) - idx) * time_per_batch\n",
        "            print(f\"\\nBatch {idx} of {len(test_dataloader)}. Elapsed: {format_time(elapsed)}\")\n",
        "            print(f\"Time left: {format_time(time_remaining)}\")\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        logits = outputs[0]\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "        predictions = np.concatenate(predictions, axis=0)\n",
        "        true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "        print('Predictions completed')\n",
        "\n",
        "        return (predictions, true_labels)"
      ],
      "metadata": {
        "id": "VaCYeOnagjX4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_on_test_set(test_dataloader, dataset_labels,\n",
        "                               saved_model_location, use_gpu, batch_print_freq\n",
        "                               ):\n",
        "\n",
        "    predictions, true_labels = run_model_on_test_set(\n",
        "        test_dataloader=test_dataloader,\n",
        "        saved_model_location=saved_model_location,\n",
        "        use_gpu=use_gpu,\n",
        "        batch_print_freq=batch_print_freq\n",
        "    )\n",
        "    pred_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "    exact_match_score = accuracy_score(true_labels, pred_labels)\n",
        "    hamming_score = hamming_loss(true_labels, pred_labels)\n",
        "\n",
        "    labels = list(dataset_labels.values())\n",
        "    target_names = list(dataset_labels.keys())\n",
        "\n",
        "    prec_recall_report = classification_report(true_labels, pred_labels, labels=labels, target_names=target_names, output_dict=True)\n",
        "\n",
        "    evaluation = {}\n",
        "    evaluation[\"exact_march_score\"] = exact_match_score\n",
        "    evaluation[\"hamming_score\"] = hamming_score\n",
        "    evaluation[\"prec_recall_report\"] = prec_recall_report\n",
        "\n",
        "    cf_matrix = confusion_matrix(true_labels, pred_labels)\n",
        "    matrix = sns.heatmap(cf_matrix, annot=True)\n",
        "    matrix.xaxis.set_ticks_position('top') \n",
        "    matrix.set(xlabel='prediction', ylabel='Gold label')\n",
        "    plt.title('Confusion Matrix\\n0=Neutral, 1=Entailment, 2=Contradiction')\n",
        "    plt.show()\n",
        "\n",
        "    print(cf_matrix)\n",
        "\n",
        "    return evaluation"
      ],
      "metadata": {
        "id": "P3binmhYR703"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, metrics = train_and_evaluate_bert(\n",
        "    BERTModel=BERTModel,\n",
        "    validation_dataloader=validation_dataloader,\n",
        "    use_gpu = True,\n",
        "    seed_value = seed_value,\n",
        "    batch_print_freq=batch_print_freq,\n",
        "    grad_clip_value=grad_clip_value\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYpFWgBHGazv",
        "outputId": "f753932e-97be-4f39-f3e0-e74f14c825ec"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available\n",
            "Using A100-SXM4-40GB\n",
            "Model, Optimizer and Scheduler setup successfully!\n",
            "Training started\n",
            "Epoch 1 / 4\n",
            "\n",
            "Batch 200 of 3433. Elapsed: 0:01:10\n",
            "Time left in this epoch: 0:18:50\n",
            "\n",
            "Batch 400 of 3433. Elapsed: 0:02:16\n",
            "Time left in this epoch: 0:17:15\n",
            "\n",
            "Batch 600 of 3433. Elapsed: 0:03:23\n",
            "Time left in this epoch: 0:15:58\n",
            "\n",
            "Batch 800 of 3433. Elapsed: 0:04:30\n",
            "Time left in this epoch: 0:14:47\n",
            "\n",
            "Batch 1000 of 3433. Elapsed: 0:05:36\n",
            "Time left in this epoch: 0:13:38\n",
            "\n",
            "Batch 1200 of 3433. Elapsed: 0:06:43\n",
            "Time left in this epoch: 0:12:29\n",
            "\n",
            "Batch 1400 of 3433. Elapsed: 0:07:49\n",
            "Time left in this epoch: 0:11:21\n",
            "\n",
            "Batch 1600 of 3433. Elapsed: 0:08:56\n",
            "Time left in this epoch: 0:10:14\n",
            "\n",
            "Batch 1800 of 3433. Elapsed: 0:10:02\n",
            "Time left in this epoch: 0:09:06\n",
            "\n",
            "Batch 2000 of 3433. Elapsed: 0:11:09\n",
            "Time left in this epoch: 0:07:59\n",
            "\n",
            "Batch 2200 of 3433. Elapsed: 0:12:15\n",
            "Time left in this epoch: 0:06:52\n",
            "\n",
            "Batch 2400 of 3433. Elapsed: 0:13:22\n",
            "Time left in this epoch: 0:05:45\n",
            "\n",
            "Batch 2600 of 3433. Elapsed: 0:14:28\n",
            "Time left in this epoch: 0:04:38\n",
            "\n",
            "Batch 2800 of 3433. Elapsed: 0:15:35\n",
            "Time left in this epoch: 0:03:31\n",
            "\n",
            "Batch 3000 of 3433. Elapsed: 0:16:41\n",
            "Time left in this epoch: 0:02:24\n",
            "\n",
            "Batch 3200 of 3433. Elapsed: 0:17:48\n",
            "Time left in this epoch: 0:01:18\n",
            "\n",
            "Batch 3400 of 3433. Elapsed: 0:18:54\n",
            "Time left in this epoch: 0:00:11\n",
            "\n",
            " Average Training Loss: 0.5283944417402135 \n",
            "Training Epoch Time: 0:19:05 \n",
            "\n",
            "Validation\n",
            "Accuracy: 0.8583265692640693\n",
            "Validation Took: 0:00:31\n",
            "Epoch 2 / 4\n",
            "\n",
            "Batch 200 of 3433. Elapsed: 0:01:07\n",
            "Time left in this epoch: 0:17:55\n",
            "\n",
            "Batch 400 of 3433. Elapsed: 0:02:13\n",
            "Time left in this epoch: 0:16:49\n",
            "\n",
            "Batch 600 of 3433. Elapsed: 0:03:20\n",
            "Time left in this epoch: 0:15:42\n",
            "\n",
            "Batch 800 of 3433. Elapsed: 0:04:26\n",
            "Time left in this epoch: 0:14:36\n",
            "\n",
            "Batch 1000 of 3433. Elapsed: 0:05:33\n",
            "Time left in this epoch: 0:13:29\n",
            "\n",
            "Batch 1200 of 3433. Elapsed: 0:06:39\n",
            "Time left in this epoch: 0:12:23\n",
            "\n",
            "Batch 1400 of 3433. Elapsed: 0:07:46\n",
            "Time left in this epoch: 0:11:16\n",
            "\n",
            "Batch 1600 of 3433. Elapsed: 0:08:52\n",
            "Time left in this epoch: 0:10:10\n",
            "\n",
            "Batch 1800 of 3433. Elapsed: 0:09:59\n",
            "Time left in this epoch: 0:09:03\n",
            "\n",
            "Batch 2000 of 3433. Elapsed: 0:11:05\n",
            "Time left in this epoch: 0:07:57\n",
            "\n",
            "Batch 2200 of 3433. Elapsed: 0:12:12\n",
            "Time left in this epoch: 0:06:50\n",
            "\n",
            "Batch 2400 of 3433. Elapsed: 0:13:18\n",
            "Time left in this epoch: 0:05:44\n",
            "\n",
            "Batch 2600 of 3433. Elapsed: 0:14:25\n",
            "Time left in this epoch: 0:04:37\n",
            "\n",
            "Batch 2800 of 3433. Elapsed: 0:15:31\n",
            "Time left in this epoch: 0:03:31\n",
            "\n",
            "Batch 3000 of 3433. Elapsed: 0:16:38\n",
            "Time left in this epoch: 0:02:24\n",
            "\n",
            "Batch 3200 of 3433. Elapsed: 0:17:44\n",
            "Time left in this epoch: 0:01:17\n",
            "\n",
            "Batch 3400 of 3433. Elapsed: 0:18:51\n",
            "Time left in this epoch: 0:00:11\n",
            "\n",
            " Average Training Loss: 0.33891871286908254 \n",
            "Training Epoch Time: 0:19:02 \n",
            "\n",
            "Validation\n",
            "Accuracy: 0.8673791486291486\n",
            "Validation Took: 0:00:31\n",
            "Epoch 3 / 4\n",
            "\n",
            "Batch 200 of 3433. Elapsed: 0:01:07\n",
            "Time left in this epoch: 0:17:56\n",
            "\n",
            "Batch 400 of 3433. Elapsed: 0:02:13\n",
            "Time left in this epoch: 0:16:50\n",
            "\n",
            "Batch 600 of 3433. Elapsed: 0:03:20\n",
            "Time left in this epoch: 0:15:43\n",
            "\n",
            "Batch 800 of 3433. Elapsed: 0:04:26\n",
            "Time left in this epoch: 0:14:37\n",
            "\n",
            "Batch 1000 of 3433. Elapsed: 0:05:33\n",
            "Time left in this epoch: 0:13:31\n",
            "\n",
            "Batch 1200 of 3433. Elapsed: 0:06:40\n",
            "Time left in this epoch: 0:12:25\n",
            "\n",
            "Batch 1400 of 3433. Elapsed: 0:07:47\n",
            "Time left in this epoch: 0:11:18\n",
            "\n",
            "Batch 1600 of 3433. Elapsed: 0:08:54\n",
            "Time left in this epoch: 0:10:12\n",
            "\n",
            "Batch 1800 of 3433. Elapsed: 0:10:01\n",
            "Time left in this epoch: 0:09:05\n",
            "\n",
            "Batch 2000 of 3433. Elapsed: 0:11:07\n",
            "Time left in this epoch: 0:07:58\n",
            "\n",
            "Batch 2200 of 3433. Elapsed: 0:12:14\n",
            "Time left in this epoch: 0:06:51\n",
            "\n",
            "Batch 2400 of 3433. Elapsed: 0:13:20\n",
            "Time left in this epoch: 0:05:44\n",
            "\n",
            "Batch 2600 of 3433. Elapsed: 0:14:27\n",
            "Time left in this epoch: 0:04:38\n",
            "\n",
            "Batch 2800 of 3433. Elapsed: 0:15:33\n",
            "Time left in this epoch: 0:03:31\n",
            "\n",
            "Batch 3000 of 3433. Elapsed: 0:16:40\n",
            "Time left in this epoch: 0:02:24\n",
            "\n",
            "Batch 3200 of 3433. Elapsed: 0:17:46\n",
            "Time left in this epoch: 0:01:18\n",
            "\n",
            "Batch 3400 of 3433. Elapsed: 0:18:53\n",
            "Time left in this epoch: 0:00:11\n",
            "\n",
            " Average Training Loss: 0.23686107123385114 \n",
            "Training Epoch Time: 0:19:04 \n",
            "\n",
            "Validation\n",
            "Accuracy: 0.8744025072150072\n",
            "Validation Took: 0:00:31\n",
            "Epoch 4 / 4\n",
            "\n",
            "Batch 200 of 3433. Elapsed: 0:01:06\n",
            "Time left in this epoch: 0:17:55\n",
            "\n",
            "Batch 400 of 3433. Elapsed: 0:02:13\n",
            "Time left in this epoch: 0:16:48\n",
            "\n",
            "Batch 600 of 3433. Elapsed: 0:03:19\n",
            "Time left in this epoch: 0:15:42\n",
            "\n",
            "Batch 800 of 3433. Elapsed: 0:04:26\n",
            "Time left in this epoch: 0:14:35\n",
            "\n",
            "Batch 1000 of 3433. Elapsed: 0:05:33\n",
            "Time left in this epoch: 0:13:29\n",
            "\n",
            "Batch 1200 of 3433. Elapsed: 0:06:39\n",
            "Time left in this epoch: 0:12:23\n",
            "\n",
            "Batch 1400 of 3433. Elapsed: 0:07:46\n",
            "Time left in this epoch: 0:11:16\n",
            "\n",
            "Batch 1600 of 3433. Elapsed: 0:08:52\n",
            "Time left in this epoch: 0:10:10\n",
            "\n",
            "Batch 1800 of 3433. Elapsed: 0:09:59\n",
            "Time left in this epoch: 0:09:03\n",
            "\n",
            "Batch 2000 of 3433. Elapsed: 0:11:05\n",
            "Time left in this epoch: 0:07:57\n",
            "\n",
            "Batch 2200 of 3433. Elapsed: 0:12:12\n",
            "Time left in this epoch: 0:06:50\n",
            "\n",
            "Batch 2400 of 3433. Elapsed: 0:13:18\n",
            "Time left in this epoch: 0:05:44\n",
            "\n",
            "Batch 2600 of 3433. Elapsed: 0:14:25\n",
            "Time left in this epoch: 0:04:37\n",
            "\n",
            "Batch 2800 of 3433. Elapsed: 0:15:31\n",
            "Time left in this epoch: 0:03:30\n",
            "\n",
            "Batch 3000 of 3433. Elapsed: 0:16:38\n",
            "Time left in this epoch: 0:02:24\n",
            "\n",
            "Batch 3200 of 3433. Elapsed: 0:17:44\n",
            "Time left in this epoch: 0:01:17\n",
            "\n",
            "Batch 3400 of 3433. Elapsed: 0:18:51\n",
            "Time left in this epoch: 0:00:11\n",
            "\n",
            " Average Training Loss: 0.1730058061242746 \n",
            "Training Epoch Time: 0:19:02 \n",
            "\n",
            "Validation\n",
            "Accuracy: 0.8717419733044733\n",
            "Validation Took: 0:00:31\n",
            "Training Complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = saved_model_location\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(f\"Saving model to {output_dir}\")\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "with open(os.path.join(output_dir, \"model-metrics.json\"), \"w\") as f:\n",
        "    model_metrics = json.dumps(metrics)\n",
        "    f.write(model_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcP34CV_nfIT",
        "outputId": "357e9241-11d2-4882-b9fd-28023ec46762"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to saved_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIUnsBt0SoyV"
      },
      "source": [
        "# Prediction and model performance checking"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing = evaluate_model_on_test_set(\n",
        "    test_dataloader=test_dataloader,\n",
        "    dataset_labels=dataset_labels,\n",
        "    saved_model_location=saved_model_location,\n",
        "    use_gpu = True,\n",
        "    batch_print_freq=batch_print_freq\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "XviYooVBH-Xz",
        "outputId": "9747c383-e6ba-4cf6-b401-d11f32d9f26d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available\n",
            "Using A100-SXM4-40GB\n",
            "Loaded pretrained model and tokenizer from saved_models\n",
            "Predictions completed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 9  0  0]\n",
            " [ 1 10  0]\n",
            " [ 0  2 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(saved_model_location + \"model-evaluation.json\", \"w\") as f:\n",
        "        output = json.dumps(testing)\n",
        "        f.write(output)"
      ],
      "metadata": {
        "id": "G1UIpjo8J9L8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "54ZMyZxrMYMp",
        "outputId": "d156762c-17c5-4a75-f679-139b11cac0de"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"exact_march_score\": 0.90625, \"hamming_score\": 0.09375, \"prec_recall_report\": {\"contradiction\": {\"precision\": 0.9, \"recall\": 1.0, \"f1-score\": 0.9473684210526316, \"support\": 9}, \"entailment\": {\"precision\": 0.8333333333333334, \"recall\": 0.9090909090909091, \"f1-score\": 0.8695652173913043, \"support\": 11}, \"neutral\": {\"precision\": 1.0, \"recall\": 0.8333333333333334, \"f1-score\": 0.9090909090909091, \"support\": 12}, \"accuracy\": 0.90625, \"macro avg\": {\"precision\": 0.9111111111111111, \"recall\": 0.9141414141414143, \"f1-score\": 0.9086748491782818, \"support\": 32}, \"weighted avg\": {\"precision\": 0.9145833333333333, \"recall\": 0.90625, \"f1-score\": 0.9062695028084045, \"support\": 32}}}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z_h31bOSi7T"
      },
      "outputs": [],
      "source": [
        "## Plot loss\n",
        "#plt.plot(list(range(1, max_epoch+1)), train_loss_, color='red', marker='o')\n",
        "#plt.plot(list(range(1, max_epoch+1)), eval_loss_, color='green', marker='^')\n",
        "#plt.gca().get_xaxis().set_major_locator(ticker.MaxNLocator(integer=True))\n",
        "#plt.title('Model loss\\nEpoch = ' + str(max_epoch))\n",
        "#plt.legend(['Train loss', 'Evaluation loss'])\n",
        "#plt.xlabel('Epoch')\n",
        "#plt.ylabel('Average cross entropy loss')\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"exact_march_score\": 0.90625\n",
        "\n",
        " \"hamming_score\": 0.09375 \n",
        " \n",
        " \"prec_recall_report\": \n",
        "\n",
        " \"contradiction\": \n",
        " \"precision\": 0.9, \"recall\": 1.0, \"f1-score\": 0.9473684210526316, \"support\": 9 \n",
        "  \n",
        "  \"entailment\": \n",
        "  \"precision\": 0.8333333333333334, \"recall\": 0.9090909090909091, \"f1-score\": 0.8695652173913043, \"support\": 11 \n",
        " \n",
        "  \"neutral\": \"precision\": 1.0, \"recall\": 0.8333333333333334, \"f1-score\": 0.9090909090909091, \"support\": 12,\n",
        "  \"accuracy\": 0.90625, \n",
        "  \n",
        "  \"macro avg\": \"precision\": 0.9111111111111111, \"recall\": 0.9141414141414143, \"f1-score\": 0.9086748491782818, \"support\": 32,\n",
        "  \n",
        "  \"weighted avg\": \"precision\": 0.9145833333333333, \"recall\": 0.90625, \"f1-score\": 0.9062695028084045, \"support\": 32"
      ],
      "metadata": {
        "id": "YQlzFDYcTmp9"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUC090gukkJBSY0rfSSWCC",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c15ebea8874443a8cc7e2776943a9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2423a23fb25a40c685e987074eec4e78",
              "IPY_MODEL_4600f4c1eedd49dfbdfde45af65c2b23",
              "IPY_MODEL_d47107159a324b1eaaf40335d0773016"
            ],
            "layout": "IPY_MODEL_f0ed889a732f46beb49a673fd15ace8d"
          }
        },
        "2423a23fb25a40c685e987074eec4e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa81b75cc94543f8915f8c4e4ab54b09",
            "placeholder": "​",
            "style": "IPY_MODEL_dce39f132650478eab0f9db9b700744f",
            "value": "Downloading: 100%"
          }
        },
        "4600f4c1eedd49dfbdfde45af65c2b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b62015e435347d3b95215d56e36905b",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3484678a37e4013b404a2d96efe7930",
            "value": 213450
          }
        },
        "d47107159a324b1eaaf40335d0773016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b136993e8fee45fda09f781333c49055",
            "placeholder": "​",
            "style": "IPY_MODEL_7f839f9c1f2d4e88a16192d288b5cfdf",
            "value": " 213k/213k [00:00&lt;00:00, 209kB/s]"
          }
        },
        "f0ed889a732f46beb49a673fd15ace8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa81b75cc94543f8915f8c4e4ab54b09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce39f132650478eab0f9db9b700744f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b62015e435347d3b95215d56e36905b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3484678a37e4013b404a2d96efe7930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b136993e8fee45fda09f781333c49055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f839f9c1f2d4e88a16192d288b5cfdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93cf2d30a6214a4aacacd4da6ee87938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79a60e17a59540f4a0bde4a877915240",
              "IPY_MODEL_cabbf70b8c2d417d9383fa52ab3a61ef",
              "IPY_MODEL_dd34b72844a0457ab29e64bad10bf6d7"
            ],
            "layout": "IPY_MODEL_629f7ab1ec0e43ec8f7f4c624d7a1807"
          }
        },
        "79a60e17a59540f4a0bde4a877915240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e53dd3a8b88342f7baa169a8130a49e8",
            "placeholder": "​",
            "style": "IPY_MODEL_a69ba5fc1ff24496a0faf27b80605fb2",
            "value": "Downloading: 100%"
          }
        },
        "cabbf70b8c2d417d9383fa52ab3a61ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6688bae75e0e4857a29dfc8094e2f075",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b74233af799403f80d381be6ca3d266",
            "value": 433
          }
        },
        "dd34b72844a0457ab29e64bad10bf6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd57080e2f1b47c98669ff21793957fd",
            "placeholder": "​",
            "style": "IPY_MODEL_ca01f29f56494b4881fd1e872d09b423",
            "value": " 433/433 [00:00&lt;00:00, 32.6kB/s]"
          }
        },
        "629f7ab1ec0e43ec8f7f4c624d7a1807": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e53dd3a8b88342f7baa169a8130a49e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a69ba5fc1ff24496a0faf27b80605fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6688bae75e0e4857a29dfc8094e2f075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b74233af799403f80d381be6ca3d266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd57080e2f1b47c98669ff21793957fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca01f29f56494b4881fd1e872d09b423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96f5df13001944b8a9251d1399275d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc5a2df76ca64be4b79cb34c873171ad",
              "IPY_MODEL_11b75ac1f4e94a20a03483ef16e30b98",
              "IPY_MODEL_6a24a55765ff4d40a3c890c3e2f21aa4"
            ],
            "layout": "IPY_MODEL_3746f1d41d624faca6ce486966684739"
          }
        },
        "fc5a2df76ca64be4b79cb34c873171ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e79996fec86d461faf06f6d04562a0f8",
            "placeholder": "​",
            "style": "IPY_MODEL_2e701e025ec34eb2bae1343aa5b3abfd",
            "value": "Downloading: 100%"
          }
        },
        "11b75ac1f4e94a20a03483ef16e30b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7be121171094d2283f930bfd653848e",
            "max": 435779157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa39eca7a2714f88a1f77cf5e14ff8cb",
            "value": 435779157
          }
        },
        "6a24a55765ff4d40a3c890c3e2f21aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74583e2b76b34df499f55685e5be0795",
            "placeholder": "​",
            "style": "IPY_MODEL_4c9f763efddd4d3eae7ee3f34230dbf7",
            "value": " 436M/436M [00:04&lt;00:00, 91.2MB/s]"
          }
        },
        "3746f1d41d624faca6ce486966684739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e79996fec86d461faf06f6d04562a0f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e701e025ec34eb2bae1343aa5b3abfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7be121171094d2283f930bfd653848e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa39eca7a2714f88a1f77cf5e14ff8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74583e2b76b34df499f55685e5be0795": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c9f763efddd4d3eae7ee3f34230dbf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}